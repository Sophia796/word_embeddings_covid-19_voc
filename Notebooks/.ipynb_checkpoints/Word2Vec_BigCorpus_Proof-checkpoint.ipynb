{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq24UvixibZR"
   },
   "source": [
    "# Covid-19-Wörter vor und nach Covid-19 - Überprüfung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmas\n",
    "- Corona\n",
    "- Maske\n",
    "- Kontaktverbot\n",
    "- Querdenker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FQnxIrfibZf"
   },
   "source": [
    "## Importe und Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIZS463EibZh",
    "outputId": "d8d8fe3f-70be-4322-a081-ba1b02ef7f2f"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import statistics \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjlyp7Bjiu60",
    "outputId": "83b51d0b-4222-48c0-ecb3-a6a2d926c0ae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "stopwords = stopwords.words('german')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus laden und vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "QaI8RPMJibZj",
    "outputId": "7a4e7af2-20e5-4048-a2b1-341f8c0a8568"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer Tr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "1  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "2  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "3  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "4  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "\n",
       "                                    ContextBefore  \\\n",
       "0                      Filmprogramme Neunkirchen.   \n",
       "1                                             NaN   \n",
       "2  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "3  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "4                      Filmprogramme Neunkirchen.   \n",
       "\n",
       "                                                 Hit  \\\n",
       "0     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "1  Von der farbkräftigen Maske (Venezianischer Tr...   \n",
       "2  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "3  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "4     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "\n",
       "                                        ContextAfter  \n",
       "0  Corona 2: \"Whoopi Sister act, eine himmlische ...  \n",
       "1                                                NaN  \n",
       "2  Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...  \n",
       "3  Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...  \n",
       "4  Corona 2: \"Whoopi Sister act, eine himmlische ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# die Datei enthält alle Treffer der oben genannten Lemmas im ZDL-Regionalkorpus des DWDS \n",
    "# mit jeweils einem Satz Kontext davor und danach\n",
    "\n",
    "df = pd.read_csv('../data/big_1993-2021.csv', sep=',', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN durch Whitespace ersetzen\n",
    "\n",
    "df = df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wörter, die mit [...] anfangen löschen\n",
    "\n",
    "expression = '\\[...]\\w*'\n",
    "df = df.replace(to_replace = expression, value = ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bevor die Spalten verbunden werden: Whitespace einfügen, um ein Aneinanderkleben der Wörter zu verhindern\n",
    "\n",
    "df['ContextBefore'] = df['ContextBefore'].astype(str) + ' '\n",
    "df['ContextAfter'] = ' ' + df['ContextAfter'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische...</td>\n",
       "      <td>Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td></td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer Tr...</td>\n",
       "      <td></td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische...</td>\n",
       "      <td>Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "1  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "2  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "3  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "4  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "\n",
       "                                     ContextBefore  \\\n",
       "0                      Filmprogramme Neunkirchen.    \n",
       "1                                                    \n",
       "2  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.    \n",
       "3  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.    \n",
       "4                      Filmprogramme Neunkirchen.    \n",
       "\n",
       "                                                 Hit  \\\n",
       "0     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "1  Von der farbkräftigen Maske (Venezianischer Tr...   \n",
       "2  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "3  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "4     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "\n",
       "                                        ContextAfter  \\\n",
       "0   Corona 2: \"Whoopi Sister act, eine himmlische...   \n",
       "1                                                      \n",
       "2   Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...   \n",
       "3   Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...   \n",
       "4   Corona 2: \"Whoopi Sister act, eine himmlische...   \n",
       "\n",
       "                                                Text  \n",
       "0  Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...  \n",
       "1    Von der farbkräftigen Maske (Venezianischer ...  \n",
       "2  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....  \n",
       "3  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....  \n",
       "4  Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text zu einer Spalte verbinden\n",
    "\n",
    "columns = ['ContextBefore', 'Hit', 'ContextAfter']\n",
    "\n",
    "df['Text'] = df[columns].astype(str).sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393699, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Größe des DF\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus shuffeln und random in der Mitte in zwei Teile teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rztg_regional</td>\n",
       "      <td>2006-12-11</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Rhein-Zeitung, 11.12.2006</td>\n",
       "      <td>weiteres Motiv vom Fastnachtsbrunnen.</td>\n",
       "      <td>Nach den \"Drei Masken\" von 2006 erinnert der n...</td>\n",
       "      <td>Was vor 40 Jahren bundesweit für Lachsal</td>\n",
       "      <td>weiteres Motiv vom Fastnachtsbrunnen. Nach d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mume_regional</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Münchner Merkur, 07.07.2020</td>\n",
       "      <td>\"Ja, seid 's Ihr narrisch? \"</td>\n",
       "      <td>\"Sterben die Menschen an Corona oder an Einsam...</td>\n",
       "      <td>Diese Frage hatte der renommierte Pflegekriti...</td>\n",
       "      <td>\"Ja, seid 's Ihr narrisch? \" \"Sterben die Mens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rztg_regional</td>\n",
       "      <td>2003-03-29</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Rhein-Zeitung, 29.03.2003</td>\n",
       "      <td>Um 15 Uhr beginnt das Derby gegen die SG Oberr...</td>\n",
       "      <td>\"Masken\" ist Motto KELLENBACH.</td>\n",
       "      <td>Der Familiengottesdienst in der evangelischen...</td>\n",
       "      <td>Um 15 Uhr beginnt das Derby gegen die SG Oberr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frt_regional</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Fränkischer Tag, 12.09.2020</td>\n",
       "      <td>Pino, der sich aber auch ungern an die unfre...</td>\n",
       "      <td>\"Und ich hoffe, dass Corona bald vorbei ist\", ...</td>\n",
       "      <td>Einige haben sich zur Lockdown-Zeit sogar wie...</td>\n",
       "      <td>Pino, der sich aber auch ungern an die unfre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rztg_regional</td>\n",
       "      <td>2004-01-27</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Rhein-Zeitung, 27.01.2004</td>\n",
       "      <td>Für die schöne Bühnengestaltung zeichnete Gerh...</td>\n",
       "      <td>Die Maske übernahm Manuela Greb und als Souffl...</td>\n",
       "      <td>Und erfreut zeigte sich auch die Vorsitzende ...</td>\n",
       "      <td>Für die schöne Bühnengestaltung zeichnete Gerh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                         Bibl  \\\n",
       "0  rztg_regional  2006-12-11  Zeitung    Rhein-Zeitung, 11.12.2006   \n",
       "1  mume_regional  2020-07-07  Zeitung  Münchner Merkur, 07.07.2020   \n",
       "2  rztg_regional  2003-03-29  Zeitung    Rhein-Zeitung, 29.03.2003   \n",
       "3   frt_regional  2020-09-12  Zeitung  Fränkischer Tag, 12.09.2020   \n",
       "4  rztg_regional  2004-01-27  Zeitung    Rhein-Zeitung, 27.01.2004   \n",
       "\n",
       "                                       ContextBefore  \\\n",
       "0             weiteres Motiv vom Fastnachtsbrunnen.    \n",
       "1                      \"Ja, seid 's Ihr narrisch? \"    \n",
       "2  Um 15 Uhr beginnt das Derby gegen die SG Oberr...   \n",
       "3    Pino, der sich aber auch ungern an die unfre...   \n",
       "4  Für die schöne Bühnengestaltung zeichnete Gerh...   \n",
       "\n",
       "                                                 Hit  \\\n",
       "0  Nach den \"Drei Masken\" von 2006 erinnert der n...   \n",
       "1  \"Sterben die Menschen an Corona oder an Einsam...   \n",
       "2                     \"Masken\" ist Motto KELLENBACH.   \n",
       "3  \"Und ich hoffe, dass Corona bald vorbei ist\", ...   \n",
       "4  Die Maske übernahm Manuela Greb und als Souffl...   \n",
       "\n",
       "                                        ContextAfter  \\\n",
       "0          Was vor 40 Jahren bundesweit für Lachsal    \n",
       "1   Diese Frage hatte der renommierte Pflegekriti...   \n",
       "2   Der Familiengottesdienst in der evangelischen...   \n",
       "3   Einige haben sich zur Lockdown-Zeit sogar wie...   \n",
       "4   Und erfreut zeigte sich auch die Vorsitzende ...   \n",
       "\n",
       "                                                Text  \n",
       "0    weiteres Motiv vom Fastnachtsbrunnen. Nach d...  \n",
       "1  \"Ja, seid 's Ihr narrisch? \" \"Sterben die Mens...  \n",
       "2  Um 15 Uhr beginnt das Derby gegen die SG Oberr...  \n",
       "3    Pino, der sich aber auch ungern an die unfre...  \n",
       "4  Für die schöne Bühnengestaltung zeichnete Gerh...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffeln \n",
    "\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196849.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "393699/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6uioii_SibZl"
   },
   "outputs": [],
   "source": [
    "# Korpus in 2 Teilkorpora (Grenze in der Mitte des geshuffelten DF)\n",
    "\n",
    "df1 = df_shuffled.iloc[:196849,:]\n",
    "df2 = df_shuffled.iloc[196850:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196850</th>\n",
       "      <td>mib_regional</td>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Mittelbayerische, 26.06.2021</td>\n",
       "      <td>Die Krux mit filetiertem Fisch</td>\n",
       "      <td>Die beiden hatten wegen Corona ungewohnt viel ...</td>\n",
       "      <td>Alessandro Papaccino, weil sein Lokal geschlo...</td>\n",
       "      <td>Die Krux mit filetiertem Fisch Die beiden hatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196851</th>\n",
       "      <td>lvz_regional</td>\n",
       "      <td>2020-12-12</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Leipziger Volkszeitung, 12.12.2020</td>\n",
       "      <td>Hunderten fremden Menschen in geschlossenen ...</td>\n",
       "      <td>Da hilft auch keine Maske mehr.</td>\n",
       "      <td>Sachsen befindet sich in einer kritischen Lage.</td>\n",
       "      <td>Hunderten fremden Menschen in geschlossenen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196852</th>\n",
       "      <td>neuw_regional</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Neue Westfälische, 29.09.2020</td>\n",
       "      <td>Den drücke ich auf der Nase immer fest.</td>\n",
       "      <td>Ich finde, die Maske ist das kleinste Problem ...</td>\n",
       "      <td>\"Hallo Hinnak, Dein Brillen-Masken-Problem is...</td>\n",
       "      <td>Den drücke ich auf der Nase immer fest. Ich fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196853</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2021</td>\n",
       "      <td>Viel mehr geht aktuell leider nicht.</td>\n",
       "      <td>Wird der Fußball nach Corona noch der gleiche ...</td>\n",
       "      <td>Ich gehe fest davon aus.</td>\n",
       "      <td>Viel mehr geht aktuell leider nicht. Wird der ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196854</th>\n",
       "      <td>ta_regional</td>\n",
       "      <td>2006-08-10</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Thüringer Allgemeine, 10.08.2006</td>\n",
       "      <td>nur noch wenige freie Plätze.</td>\n",
       "      <td>Es ist aber auch zu verlockend, Kostüme und Ma...</td>\n",
       "      <td></td>\n",
       "      <td>nur noch wenige freie Plätze. Es ist aber au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Corpus        Date    Genre  \\\n",
       "196850   mib_regional  2021-06-26  Zeitung   \n",
       "196851   lvz_regional  2020-12-12  Zeitung   \n",
       "196852  neuw_regional  2020-09-29  Zeitung   \n",
       "196853    sk_regional  2021-02-01  Zeitung   \n",
       "196854    ta_regional  2006-08-10  Zeitung   \n",
       "\n",
       "                                      Bibl  \\\n",
       "196850        Mittelbayerische, 26.06.2021   \n",
       "196851  Leipziger Volkszeitung, 12.12.2020   \n",
       "196852       Neue Westfälische, 29.09.2020   \n",
       "196853               Südkurier, 01.02.2021   \n",
       "196854    Thüringer Allgemeine, 10.08.2006   \n",
       "\n",
       "                                            ContextBefore  \\\n",
       "196850                    Die Krux mit filetiertem Fisch    \n",
       "196851    Hunderten fremden Menschen in geschlossenen ...   \n",
       "196852           Den drücke ich auf der Nase immer fest.    \n",
       "196853              Viel mehr geht aktuell leider nicht.    \n",
       "196854                     nur noch wenige freie Plätze.    \n",
       "\n",
       "                                                      Hit  \\\n",
       "196850  Die beiden hatten wegen Corona ungewohnt viel ...   \n",
       "196851                    Da hilft auch keine Maske mehr.   \n",
       "196852  Ich finde, die Maske ist das kleinste Problem ...   \n",
       "196853  Wird der Fußball nach Corona noch der gleiche ...   \n",
       "196854  Es ist aber auch zu verlockend, Kostüme und Ma...   \n",
       "\n",
       "                                             ContextAfter  \\\n",
       "196850   Alessandro Papaccino, weil sein Lokal geschlo...   \n",
       "196851    Sachsen befindet sich in einer kritischen Lage.   \n",
       "196852   \"Hallo Hinnak, Dein Brillen-Masken-Problem is...   \n",
       "196853                           Ich gehe fest davon aus.   \n",
       "196854                                                      \n",
       "\n",
       "                                                     Text  \n",
       "196850  Die Krux mit filetiertem Fisch Die beiden hatt...  \n",
       "196851    Hunderten fremden Menschen in geschlossenen ...  \n",
       "196852  Den drücke ich auf der Nase immer fest. Ich fi...  \n",
       "196853  Viel mehr geht aktuell leider nicht. Wird der ...  \n",
       "196854    nur noch wenige freie Plätze. Es ist aber au...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hilfsfunktionen zur Vorbereitung der Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text_column(df, column):\n",
    "    \"\"\"\n",
    "    transforms the Dataframe-column in a lemmatized string\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        lemmas = ' '.join([x.lemma_ for x in doc])\n",
    "        text = text + lemmas\n",
    "    return text\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_äÄöÖüÜß]',' ', raw).split()                              \n",
    "    filtered_text = [word for word in text if word not in stopwords]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of tokenized sentences\n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    phrases = Phrases(tokenized_sentences)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = list(bigram[tokenized_sentences])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des ersten Texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uVMUJzlpibZo",
    "outputId": "d9d2a45d-3e51-41e2-83a8-decaed115ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhs', 'haus', 'kontaktfreier', 'sport', 'erlauben', 'heißen', 'paartanzkurse', 'geben']\n"
     ]
    }
   ],
   "source": [
    "text = lemmatize_text_column(df1, 'Text')\n",
    "sentences = prepare_text(text)\n",
    "\n",
    "# sentences ist eine Liste von tokenisierten Sätzen, zum Beispiel:\n",
    "print(sentences[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des zweiten Texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['günter', 'meist', 'helferinnen', 'stamm', 'besatzung', 'bereits', 'jahr_alt', 'teil', 'corona', 'impfen', 'verein', 'communitas', 'kurzfristig', 'mannschaft', 'jung', 'mitglied', 'katholisch', 'kirchgemeinde', 'hainichen', 'mitarbeiter', 'firma', 'naturbrennstoffe', 'sowie', 'geimpfte_genesene', 'zusammenstellen']\n"
     ]
    }
   ],
   "source": [
    "text2 = lemmatize_text_column(df2, 'Text')            \n",
    "sentences2 = prepare_text(text2)\n",
    "\n",
    "print(sentences2[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training von Word2Vec auf den Text vor Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HI1V5EARibZo"
   },
   "outputs": [],
   "source": [
    "# Paramter setzen\n",
    "workers = 4                      # Use these many worker threads to train the model (=faster training with multicore machines)\n",
    "seed = 42                        # Seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gWLaiZ5cibZq"
   },
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kpbrlbf0ibZq",
    "outputId": "1f537e5c-add4-40c4-8b31-49c6f8869309"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "w2v1 = Word2Vec(sentences=sentences,                   \n",
    "                 vector_size=300,          # Dimensionality of the word vectors\n",
    "                 window=10,                # The maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=3,              # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,         # Learning rate will linearly drop to min_alpha as training progresses\n",
    "                 sg=1,                     # Training algorithm: skip-gram if sg=1, otherwise CBOW\n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH8M_UkAibZr"
   },
   "source": [
    "## Training von Word2Vec auf den Text nach Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Gfy3LgWyibZt",
    "outputId": "0962a7be-cecd-4c1f-a1e0-ba52aff1fdc1"
   },
   "outputs": [],
   "source": [
    "w2v2 = Word2Vec(sentences=sentences2,                   \n",
    "                 vector_size=300,                \n",
    "                 window=10,              \n",
    "                 min_count=3,             \n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,                                                    \n",
    "                 sg=1,                     \n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle speichern\n",
    "w2v1.save(os.path.join('../trained_models', 'w2v1_big_proof.model'))\n",
    "w2v2.save(os.path.join('../trained_models', 'w2v2_big_proof.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration und Vergleich der Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle laden\n",
    "w2v1 = Word2Vec.load(os.path.join('../trained_models', 'w2v1_big_proof.model'))\n",
    "w2v2 = Word2Vec.load(os.path.join('../trained_models', 'w2v2_big_proof.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "okTISay5ibZv",
    "outputId": "8f2fe288-c8ba-4abc-881f-a2ed7c6e69f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('querdenkern', 0.6588187217712402),\n",
       " ('querdenken', 0.5921803712844849),\n",
       " ('vordenker', 0.5727674961090088),\n",
       " ('heiner_geißler', 0.5653073787689209),\n",
       " ('querulant', 0.5647078156471252),\n",
       " ('corona_leugner', 0.5592082738876343),\n",
       " ('partei', 0.557693362236023),\n",
       " ('politisch', 0.5558976531028748),\n",
       " ('querdenkers', 0.5428187251091003),\n",
       " ('verschwörungstheoretiker', 0.5397461652755737),\n",
       " ('karl_valentin', 0.5366318821907043),\n",
       " ('kritiker', 0.5350196957588196),\n",
       " ('rechtsextremisten', 0.5320907235145569),\n",
       " ('demonstration_sogenannt', 0.5311106443405151),\n",
       " ('polit', 0.5246793031692505),\n",
       " ('sogenannt_querdenker', 0.5239007472991943),\n",
       " ('rebell', 0.5235471129417419),\n",
       " ('quertreiber', 0.5217278599739075),\n",
       " ('antisemit', 0.521049439907074),\n",
       " ('these', 0.5172858238220215)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['querdenker'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "twofLe79ibZw",
    "outputId": "baea5bc0-fcdb-4e83-c22c-37853c505e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('querdenkern', 0.7085202932357788),\n",
       " ('corona_leugner', 0.5580762624740601),\n",
       " ('sogenannt_querdenker', 0.5412794947624207),\n",
       " ('querdenkers', 0.5407152771949768),\n",
       " ('querdenken', 0.5391135811805725),\n",
       " ('afd', 0.5356047749519348),\n",
       " ('politisch', 0.527485191822052),\n",
       " ('rebell', 0.5081558227539062),\n",
       " ('protest', 0.5001971125602722),\n",
       " ('zweifler', 0.4995787739753723),\n",
       " ('demokratie', 0.4959101378917694),\n",
       " ('kundgebung', 0.49128445982933044),\n",
       " ('kritiker', 0.4812290072441101),\n",
       " ('grundrechte', 0.48046866059303284),\n",
       " ('partei', 0.48032793402671814),\n",
       " ('leicht_einsteiger', 0.4801614582538605),\n",
       " ('schwierig_profi', 0.47835060954093933),\n",
       " ('demo', 0.47694069147109985),\n",
       " ('demonstration', 0.4760800004005432),\n",
       " ('ernannt_querdenker', 0.4753364622592926)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['querdenker'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dcorona', 0.6397215127944946),\n",
       " ('ausnahmezustand', 0.6325564980506897),\n",
       " ('euphorie', 0.617592453956604),\n",
       " ('ansprechpartner_redaktion', 0.6169363260269165),\n",
       " ('veder', 0.615837574005127),\n",
       " ('niedrige', 0.6138754487037659),\n",
       " ('wbf', 0.6082111597061157),\n",
       " ('geschäftslage', 0.6067193150520325),\n",
       " ('ve', 0.6046144366264343),\n",
       " ('steigen_nachfrage', 0.601384699344635),\n",
       " ('kreis_haßberge', 0.5981872081756592),\n",
       " ('zweite_lockdown', 0.5974642634391785),\n",
       " ('griff_behalten', 0.5973573327064514),\n",
       " ('verschmerzen', 0.5969419479370117),\n",
       " ('bundespolitik', 0.594907283782959),\n",
       " ('fluß', 0.5925443768501282),\n",
       " ('tagesgästen', 0.591491162776947),\n",
       " ('pflegeheimbewohner', 0.5908797979354858),\n",
       " ('durchboxen', 0.5884109139442444),\n",
       " ('kulturell_veranstaltung', 0.5878657698631287)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['corona'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('einge', 0.6254350543022156),\n",
       " ('gesundheitsam', 0.6170993447303772),\n",
       " ('impfstrategie', 0.6094528436660767),\n",
       " ('stadt_schongauer', 0.6055542230606079),\n",
       " ('epd', 0.602095365524292),\n",
       " ('leichter', 0.5991912484169006),\n",
       " ('existenznöte', 0.5966088175773621),\n",
       " ('mehr_lohn', 0.5956728458404541),\n",
       " ('personalaufwand', 0.59549480676651),\n",
       " ('seuche', 0.5954253673553467),\n",
       " ('kolleg', 0.5927336812019348),\n",
       " ('blumberg_blu', 0.591993510723114),\n",
       " ('auftragsbücher_voll', 0.5918238759040833),\n",
       " ('uin', 0.590897262096405),\n",
       " ('rathau', 0.5896192789077759),\n",
       " ('kreis_altenkirchen', 0.5891485810279846),\n",
       " ('dcorona', 0.5877975821495056),\n",
       " ('drogenszene', 0.5874871611595154),\n",
       " ('wirtschaftlich_gesellschaftlich', 0.5872811675071716),\n",
       " ('lehrbetrieb', 0.5858713984489441)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['corona'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gesichtsmaske', 0.6178276538848877),\n",
       " ('gesichts', 0.5856296420097351),\n",
       " ('make_up', 0.5816360116004944),\n",
       " ('utensil', 0.5742040276527405),\n",
       " ('mantel', 0.573429524898529),\n",
       " ('gefertigt_maske', 0.5727666616439819),\n",
       " ('perücke', 0.5722976922988892),\n",
       " ('mitgebracht', 0.5713409781455994),\n",
       " ('kleidungsstücke', 0.5710033774375916),\n",
       " ('bändern', 0.5700575709342957),\n",
       " ('holzmaske', 0.5694084763526917),\n",
       " ('gschell', 0.5669103860855103),\n",
       " ('handschuh', 0.5634407997131348),\n",
       " ('nase_mund', 0.5632302761077881),\n",
       " ('zubehör', 0.5630552172660828),\n",
       " ('umhang', 0.5616921782493591),\n",
       " ('davon_zeugen', 0.5614191293716431),\n",
       " ('hose_jacke', 0.5584930777549744),\n",
       " ('gummi', 0.5580463409423828),\n",
       " ('bettlaken', 0.5569013357162476)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['maske'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gesichtsmaske', 0.5714719295501709),\n",
       " ('gefertigt_maske', 0.5633559823036194),\n",
       " ('perücke', 0.5588682889938354),\n",
       " ('atemschutzmaske', 0.5575581789016724),\n",
       " ('bilderrahmen', 0.5496194958686829),\n",
       " ('kopfbedeckung', 0.5490328669548035),\n",
       " ('ähnlichem', 0.5484027862548828),\n",
       " ('seide', 0.5476992130279541),\n",
       " ('bändern', 0.5468208193778992),\n",
       " ('tuch', 0.5460397601127625),\n",
       " ('umhang', 0.5445458292961121),\n",
       " ('angefertigt', 0.5440043210983276),\n",
       " ('kaffeefilter', 0.5439320802688599),\n",
       " ('mütze', 0.5437399744987488),\n",
       " ('hergestellt_maske', 0.5432673096656799),\n",
       " ('ausschneiden', 0.5428699851036072),\n",
       " ('leder', 0.5421731472015381),\n",
       " ('vorderseite', 0.5413904190063477),\n",
       " ('klebstoff', 0.540919840335846),\n",
       " ('klamotte', 0.5403167009353638)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['maske'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kontaktverbote', 0.7869566679000854),\n",
       " ('kontaktverbots', 0.7335948348045349),\n",
       " ('kontaktverbotes', 0.7061266303062439),\n",
       " ('verhängen', 0.6898846626281738),\n",
       " ('ex_freundin', 0.687829852104187),\n",
       " ('erwirken', 0.6867323517799377),\n",
       " ('angeklagte', 0.6805453300476074),\n",
       " ('gerichtlich', 0.6761641502380371),\n",
       " ('verhängen_kontaktverbot', 0.6505555510520935),\n",
       " ('gerichtlich_kontaktverbot', 0.6450782418251038),\n",
       " ('gewaltschutzgesetz', 0.6401407718658447),\n",
       " ('richterlich', 0.6382237076759338),\n",
       " ('geschieden', 0.6379993557929993),\n",
       " ('familiengericht', 0.6362400650978088),\n",
       " ('kontaktverbot_aussprechen', 0.6318796277046204),\n",
       " ('haftbefehl', 0.6298323273658752),\n",
       " ('sexuell', 0.6280562877655029),\n",
       " ('amtsgericht', 0.6275899410247803),\n",
       " ('richterliche', 0.62645423412323),\n",
       " ('ausgangsbeschränkungen', 0.6260154247283936)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['kontaktverbot'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kontaktverbote', 0.7696318030357361),\n",
       " ('kontaktverbots', 0.7158422470092773),\n",
       " ('erwirken', 0.6866025924682617),\n",
       " ('familiengericht', 0.6779651045799255),\n",
       " ('gerichtlich_kontaktverbot', 0.6689993739128113),\n",
       " ('kontaktverbot_aussprechen', 0.6637488007545471),\n",
       " ('verhängen', 0.6621763706207275),\n",
       " ('platzverweis', 0.6494439840316772),\n",
       " ('gewaltschutzgesetz', 0.6489607095718384),\n",
       " ('strikt_kontaktverbot', 0.6485754251480103),\n",
       " ('gerichtlich', 0.6472131609916687),\n",
       " ('kontaktverbotes', 0.6461856365203857),\n",
       " ('kontaktverbot_verhängen', 0.6368775367736816),\n",
       " ('ex_freundin', 0.6336828470230103),\n",
       " ('gemeinsam_wohnung', 0.6293594241142273),\n",
       " ('angeklagte', 0.6289194822311401),\n",
       " ('kontaktverboten', 0.626443088054657),\n",
       " ('platzverweis_kontaktverbot', 0.6240734457969666),\n",
       " ('verhängt', 0.622042715549469),\n",
       " ('gericht_kontaktverbot', 0.6219041347503662)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['kontaktverbot'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('krankheit', 0.6362794041633606),\n",
       " ('coronavirus', 0.6236957907676697),\n",
       " ('covid', 0.6212191581726074),\n",
       " ('ausbreitung', 0.6013243794441223),\n",
       " ('epidemie', 0.5913169384002686),\n",
       " ('infektion', 0.5746894478797913),\n",
       " ('delta_variante', 0.5740849375724792),\n",
       " ('seuche', 0.5692173838615417),\n",
       " ('befallen', 0.5659627914428711),\n",
       " ('schlaganfall', 0.5565125346183777),\n",
       " ('ansteckend', 0.556220531463623),\n",
       " ('klinikalltag', 0.5517795085906982),\n",
       " ('grippe', 0.5503295063972473),\n",
       " ('sars_cov', 0.5500518083572388),\n",
       " ('bekämpfen', 0.5473859906196594),\n",
       " ('verbreitung_virus', 0.5473832488059998),\n",
       " ('infektionskrankheit', 0.5465611219406128),\n",
       " ('hiv', 0.5439268946647644),\n",
       " ('unwissentlich', 0.5424239635467529),\n",
       " ('aids', 0.5417110323905945)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v1.wv.most_similar(positive=['virus'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('covid', 0.6802770495414734),\n",
       " ('coronavirus', 0.6208800077438354),\n",
       " ('grippe', 0.5916258692741394),\n",
       " ('krankheit', 0.5829752087593079),\n",
       " ('influenza', 0.5802415609359741),\n",
       " ('erreger', 0.5790480375289917),\n",
       " ('infektion', 0.5716615915298462),\n",
       " ('epidemie', 0.5690684914588928),\n",
       " ('ausbreitung', 0.5649843215942383),\n",
       " ('sars_cov', 0.5641929507255554),\n",
       " ('zelle', 0.5526627898216248),\n",
       " ('verbreitung', 0.5519125461578369),\n",
       " ('ausbreiten', 0.5458496809005737),\n",
       " ('ansteckend', 0.5422831177711487),\n",
       " ('seuche', 0.5406694412231445),\n",
       " ('virus_bakterie', 0.540645956993103),\n",
       " ('erkältung', 0.5399212837219238),\n",
       " ('vogelgrippe', 0.5397496223449707),\n",
       " ('viren', 0.5388253331184387),\n",
       " ('hepatitis', 0.5312572717666626)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v2.wv.most_similar(positive=['virus'], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausrichtung der beiden Embedding-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Updatet script: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "    Procrustes align two gensim models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
    "    # base_embed.init_sims(replace=True)\n",
    "    # other_embed.init_sims(replace=True)\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "    \n",
    "    # re-filling the normed vectors\n",
    "    in_base_embed.wv.fill_norms(force=True)\n",
    "    in_other_embed.wv.fill_norms(force=True)\n",
    "\n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n",
    "\n",
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57557 57557\n",
      "57557 57557\n"
     ]
    }
   ],
   "source": [
    "# Ausrichtung der beiden Modelle\n",
    "\n",
    "w2v2_al = smart_procrustes_align_gensim(w2v1, w2v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern\n",
    "w2v2_al.save(os.path.join('../trained_models', 'w2v2_al_big.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus-Ähnlichkeit zwischen den Vektoren der beiden Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laden\n",
    "w2v2_al = Word2Vec.load(os.path.join('../trained_models', 'w2v2_al_big.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('querdenkern', 0.7085202932357788),\n",
       " ('corona_leugner', 0.5580762624740601),\n",
       " ('sogenannt_querdenker', 0.5412795543670654),\n",
       " ('querdenkers', 0.5407153367996216),\n",
       " ('querdenken', 0.5391135811805725),\n",
       " ('afd', 0.5356048941612244),\n",
       " ('politisch', 0.527485191822052),\n",
       " ('rebell', 0.508155882358551),\n",
       " ('protest', 0.5001971125602722),\n",
       " ('zweifler', 0.4995788335800171),\n",
       " ('demokratie', 0.495910108089447),\n",
       " ('kundgebung', 0.4912845194339752),\n",
       " ('kritiker', 0.4812290072441101),\n",
       " ('grundrechte', 0.4804686903953552),\n",
       " ('partei', 0.4803280234336853),\n",
       " ('demo', 0.47694069147109985),\n",
       " ('demonstration', 0.4760799705982208),\n",
       " ('ernannt_querdenker', 0.4753364622592926),\n",
       " ('unbequem_querdenker', 0.475033700466156),\n",
       " ('politik', 0.47353753447532654),\n",
       " ('kassel', 0.4722203314304352),\n",
       " ('reichsbürger', 0.4718503952026367),\n",
       " ('telegram', 0.47115880250930786),\n",
       " ('kritik', 0.4673141539096832),\n",
       " ('rechtsextremisten', 0.46617376804351807)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' nach Covid-19\n",
    "w2v2_al.wv.most_similar(positive=['querdenker'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8308195471763611"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_querdenker1 = w2v1.wv['querdenker']  \n",
    "vector_querdenker2_al = w2v2_al.wv['querdenker'] \n",
    "\n",
    "cosine_querdenker = 1 - spatial.distance.cosine(vector_querdenker1, vector_querdenker2_al)\n",
    "cosine_querdenker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9374611973762512"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_maske1 = w2v1.wv['maske']  \n",
    "vector_maske2_al = w2v2_al.wv['maske'] \n",
    "\n",
    "cosine_maske = 1 - spatial.distance.cosine(vector_maske1, vector_maske2_al)\n",
    "cosine_maske"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8911445736885071"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_kontaktverbot1 = w2v1.wv['kontaktverbot']  \n",
    "vector_kontaktverbot2_al = w2v2_al.wv['kontaktverbot'] \n",
    "\n",
    "cosine_kontaktverbot = 1 - spatial.distance.cosine(vector_kontaktverbot1, vector_kontaktverbot2_al)\n",
    "cosine_kontaktverbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9364716410636902"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_corona1 = w2v1.wv['corona']  \n",
    "vector_corona2_al = w2v2_al.wv['corona'] \n",
    "\n",
    "cosine_corona = 1 - spatial.distance.cosine(vector_corona1, vector_corona2_al)\n",
    "cosine_corona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7904312610626221"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versuch mit unverfänglichen Wörtern\n",
    "\n",
    "vector_deutschland1 = w2v1.wv['deutschland']  \n",
    "vector_deutschland2_al = w2v2_al.wv['deutschland'] \n",
    "\n",
    "cosine_deutschland = 1 - spatial.distance.cosine(vector_deutschland1, vector_deutschland2_al)\n",
    "cosine_deutschland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412572741508484"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_nachricht1 = w2v1.wv['nachricht']  \n",
    "vector_nachricht2_al = w2v2_al.wv['nachricht'] \n",
    "\n",
    "cosine_nachricht = 1 - spatial.distance.cosine(vector_nachricht1, vector_nachricht2_al)\n",
    "cosine_nachricht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7881110906600952"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mann1 = w2v1.wv['mann']  \n",
    "vector_mann2_al = w2v2_al.wv['mann'] \n",
    "\n",
    "cosine_mann = 1 - spatial.distance.cosine(vector_mann1, vector_mann2_al)\n",
    "cosine_mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8224247694015503"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_frau1 = w2v1.wv['frau']  \n",
    "vector_frau2_al = w2v2_al.wv['frau'] \n",
    "\n",
    "cosine_frau = 1 - spatial.distance.cosine(vector_frau1, vector_frau2_al)\n",
    "cosine_frau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### durchschnittliche Cosinus-Ähnlichkeit, Standardweichung und 'Normalbereich'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- von allen Wörtern/Vektoren, die in beiden Modellen vorkommen jeweils die Cosinus-Ähnlichkeit berechnen (also zueinander zwischen den Modellen)\n",
    "- durchschnittliche Ähnlichkeit und Standardabweichung berechnen, um einen 'Normalbereich' zu ermitteln\n",
    "- liegt der Wert der Cosinus-Ähnlichkeit (desselben Lemmas zwischen den Modellen) unter dem Normalbereich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle Wörter, die in beiden Modellen vorkommmen\n",
    "\n",
    "vocab1 = set(w2v1.wv.index_to_key)\n",
    "vocab2_al = set(w2v2_al.wv.index_to_key)\n",
    "\n",
    "common_vocab = vocab1 & vocab2_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57557"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosinus-Ähnlichkeit zwischen dem Wort in den beiden Modellen berechnen\n",
    "\n",
    "cosines = {}\n",
    "\n",
    "for word in common_vocab:\n",
    "    vector1 = w2v1.wv[word]  \n",
    "    vector2_al = w2v2_al.wv[word] \n",
    "    cosine = 1 - spatial.distance.cosine(vector1, vector2_al)\n",
    "    cosines[word] = cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>verstohlen</th>\n",
       "      <td>0.945939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gesprächsbedarf</th>\n",
       "      <td>0.907328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kopfhaut</th>\n",
       "      <td>0.933847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weiterverfolgen</th>\n",
       "      <td>0.912821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwangs</th>\n",
       "      <td>0.942296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parallele</th>\n",
       "      <td>0.902846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domhof</th>\n",
       "      <td>0.903463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kindergartenkind</th>\n",
       "      <td>0.890936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fadenscheinig</th>\n",
       "      <td>0.922577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angermuseum</th>\n",
       "      <td>0.897668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57557 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cosine\n",
       "verstohlen        0.945939\n",
       "gesprächsbedarf   0.907328\n",
       "kopfhaut          0.933847\n",
       "weiterverfolgen   0.912821\n",
       "zwangs            0.942296\n",
       "...                    ...\n",
       "parallele         0.902846\n",
       "domhof            0.903463\n",
       "kindergartenkind  0.890936\n",
       "fadenscheinig     0.922577\n",
       "angermuseum       0.897668\n",
       "\n",
       "[57557 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df = pd.DataFrame.from_dict(cosines, orient='index', columns=['cosine'])\n",
    "cosine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938241987028089"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# durchschnittliche Cosinus-Ähnlichkeit der Wörter der beiden Modelle \n",
    "\n",
    "statistics.mean(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055511105889167855"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardabweichung\n",
    "\n",
    "statistics.stdev(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Normalbereich der Cosinus-Ähnlichkeit liegt über 0.8383130928136411\n"
     ]
    }
   ],
   "source": [
    "# 'Normalbereich' der Cosinus-Ähnlichkeit\n",
    "\n",
    "border = statistics.mean(cosine_df['cosine']) - statistics.stdev(cosine_df['cosine'])\n",
    "\n",
    "print('der Normalbereich der Cosinus-Ähnlichkeit liegt über', border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>burg_betriebsferien</th>\n",
       "      <td>0.028445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buedingen</th>\n",
       "      <td>0.031238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coro</th>\n",
       "      <td>0.408289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selbsthilfegruppen_geben</th>\n",
       "      <td>0.415310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeweils_immer</th>\n",
       "      <td>0.424558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teil_veröffentlichen</th>\n",
       "      <td>0.434795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zweibrücken</th>\n",
       "      <td>0.464220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vorab_kontaktaufnahme</th>\n",
       "      <td>0.474344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.476515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>einrichtung_gebeten</th>\n",
       "      <td>0.483769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enger_rödinghausen</th>\n",
       "      <td>0.488284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ge</th>\n",
       "      <td>0.491636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schloß_holte</th>\n",
       "      <td>0.525383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiddenhausen_kirchlengern</th>\n",
       "      <td>0.535374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strüverweg_soers</th>\n",
       "      <td>0.540920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>0.548572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad_sulza</th>\n",
       "      <td>0.556262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_pers</th>\n",
       "      <td>0.556644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grosse</th>\n",
       "      <td>0.560033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traumreisen_bildergeschichten</th>\n",
       "      <td>0.562922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>st_johann</th>\n",
       "      <td>0.565687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ökumenische_nachbarschaftshilfe</th>\n",
       "      <td>0.567401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rüdesheim</th>\n",
       "      <td>0.569980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metropolregion_geben</th>\n",
       "      <td>0.579285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emil_detektiv</th>\n",
       "      <td>0.584431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.588861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>0.590233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schongauer_helfen</th>\n",
       "      <td>0.591225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tobi</th>\n",
       "      <td>0.591786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berg</th>\n",
       "      <td>0.592085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cosine\n",
       "burg_betriebsferien              0.028445\n",
       "buedingen                        0.031238\n",
       "coro                             0.408289\n",
       "selbsthilfegruppen_geben         0.415310\n",
       "jeweils_immer                    0.424558\n",
       "teil_veröffentlichen             0.434795\n",
       "zweibrücken                      0.464220\n",
       "vorab_kontaktaufnahme            0.474344\n",
       "h                                0.476515\n",
       "einrichtung_gebeten              0.483769\n",
       "enger_rödinghausen               0.488284\n",
       "ge                               0.491636\n",
       "schloß_holte                     0.525383\n",
       "hiddenhausen_kirchlengern        0.535374\n",
       "strüverweg_soers                 0.540920\n",
       "image                            0.548572\n",
       "bad_sulza                        0.556262\n",
       "m_pers                           0.556644\n",
       "grosse                           0.560033\n",
       "traumreisen_bildergeschichten    0.562922\n",
       "st_johann                        0.565687\n",
       "ökumenische_nachbarschaftshilfe  0.567401\n",
       "rüdesheim                        0.569980\n",
       "metropolregion_geben             0.579285\n",
       "emil_detektiv                    0.584431\n",
       "paris                            0.588861\n",
       "ni                               0.590233\n",
       "schongauer_helfen                0.591225\n",
       "tobi                             0.591786\n",
       "berg                             0.592085"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF aufsteigend sortieren und die ersten 30 Zeilen ausgeben, um die 'Ausreißer' anzuschauen\n",
    "# nur um mal zu gucken...\n",
    "\n",
    "cosine_df.sort_values(by=['cosine'], axis=0).iloc[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie erwartet ist Cosinus-Ähnlichkeit zwischen den Vektoren 'Querdenker', 'Corona', 'Kontaktverbot' und 'Maske' zwischen den geshuffelten Modellen jeweils höher als zwischen dem Before- und After-Covid-Modell. <br>\n",
    "Der Test bestätigt nochmal die Hypothese."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext Corona.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
