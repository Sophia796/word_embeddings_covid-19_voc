{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq24UvixibZR"
   },
   "source": [
    "# Covid-19-Wörter vor und nach Covid-19 - eine Untersuchung mit Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmas\n",
    "- Corona\n",
    "- Maske\n",
    "- Kontaktverbot\n",
    "- Querdenker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FQnxIrfibZf"
   },
   "source": [
    "## Importe und Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIZS463EibZh",
    "outputId": "d8d8fe3f-70be-4322-a081-ba1b02ef7f2f"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import statistics \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjlyp7Bjiu60",
    "outputId": "83b51d0b-4222-48c0-ecb3-a6a2d926c0ae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "stopwords = stopwords.words('german')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus laden und teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "QaI8RPMJibZj",
    "outputId": "7a4e7af2-20e5-4048-a2b1-341f8c0a8568"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer Tr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "1  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "2  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "3  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "4  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "\n",
       "                                    ContextBefore  \\\n",
       "0                      Filmprogramme Neunkirchen.   \n",
       "1                                             NaN   \n",
       "2  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "3  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "4                      Filmprogramme Neunkirchen.   \n",
       "\n",
       "                                                 Hit  \\\n",
       "0     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "1  Von der farbkräftigen Maske (Venezianischer Tr...   \n",
       "2  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "3  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "4     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "\n",
       "                                        ContextAfter  \n",
       "0  Corona 2: \"Whoopi Sister act, eine himmlische ...  \n",
       "1                                                NaN  \n",
       "2  Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...  \n",
       "3  Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte ...  \n",
       "4  Corona 2: \"Whoopi Sister act, eine himmlische ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# die Datei enthält alle Treffer der oben genannten Lemmas im ZDL-Regionalkorpus des DWDS \n",
    "# mit jeweils einem Satz Kontext davor und danach\n",
    "\n",
    "df = pd.read_csv('../data/big_1993-2021.csv', sep=',', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN durch Whitespace ersetzen\n",
    "\n",
    "df = df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wörter, die mit [...] anfangen löschen\n",
    "\n",
    "expression = '\\[...]\\w*'\n",
    "df = df.replace(to_replace = expression, value = ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bevor die Spalten verbunden werden: Whitespace einfügen, um ein Aneinanderkleben der Wörter zu verhindern\n",
    "\n",
    "df['ContextBefore'] = df['ContextBefore'].astype(str) + ' '\n",
    "df['ContextAfter'] = ' ' + df['ContextAfter'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische...</td>\n",
       "      <td>Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td></td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer Tr...</td>\n",
       "      <td></td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische ...</td>\n",
       "      <td>Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 03.02.1993</td>\n",
       "      <td>Filmprogramme Neunkirchen.</td>\n",
       "      <td>Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.</td>\n",
       "      <td>Corona 2: \"Whoopi Sister act, eine himmlische...</td>\n",
       "      <td>Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "1  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "2  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "3  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "4  saar_regional  1993-02-03  Zeitung  Saarbrücker Zeitung, 03.02.1993   \n",
       "\n",
       "                                     ContextBefore  \\\n",
       "0                      Filmprogramme Neunkirchen.    \n",
       "1                                                    \n",
       "2  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.    \n",
       "3  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.    \n",
       "4                      Filmprogramme Neunkirchen.    \n",
       "\n",
       "                                                 Hit  \\\n",
       "0     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "1  Von der farbkräftigen Maske (Venezianischer Tr...   \n",
       "2  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "3  Corona 2: \"Whoopi Sister act, eine himmlische ...   \n",
       "4     Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr.   \n",
       "\n",
       "                                        ContextAfter  \\\n",
       "0   Corona 2: \"Whoopi Sister act, eine himmlische...   \n",
       "1                                                      \n",
       "2   Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...   \n",
       "3   Burg 1:15.15, 17.45 und 20.15 Uhr \"Der letzte...   \n",
       "4   Corona 2: \"Whoopi Sister act, eine himmlische...   \n",
       "\n",
       "                                                Text  \n",
       "0  Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...  \n",
       "1    Von der farbkräftigen Maske (Venezianischer ...  \n",
       "2  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....  \n",
       "3  Corona 1: \"Bodyguard\" 15.30, 17.45, 20.15 Uhr....  \n",
       "4  Filmprogramme Neunkirchen. Corona 1: \"Bodyguar...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text zu einer Spalte verbinden\n",
    "\n",
    "columns = ['ContextBefore', 'Hit', 'ContextAfter']\n",
    "\n",
    "df['Text'] = df[columns].astype(str).sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393699, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Größe des DF\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6uioii_SibZl"
   },
   "outputs": [],
   "source": [
    "# Korpus in 2 Teilkorpora splitten: vor und nach Covid-19 (dem Ausbruch in Deutschland)\n",
    "# hier wurde die Grenze zwischen Januar und Februar 2020 gezogen (es wird sich noch zeigen, inwiefern sich das bewährt)\n",
    "\n",
    "df_before_corona = df.iloc[:91191,:]\n",
    "df_after_corona = df.iloc[91192:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91192</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2020</td>\n",
       "      <td>Gründungsmitglieder, die sogenannten Gelbjac...</td>\n",
       "      <td>In ihrer Nachfolge gibt es seit 1993 die Gelbj...</td>\n",
       "      <td>Sie haben 33 Mitglieder.</td>\n",
       "      <td>Gründungsmitglieder, die sogenannten Gelbjac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91193</th>\n",
       "      <td>mib_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Mittelbayerische, 01.02.2020</td>\n",
       "      <td>Am Flughafen kam dann die Ernüchterung:</td>\n",
       "      <td>\"Alle tatschen dich an, keiner trägt eine Maske.</td>\n",
       "      <td>Ich war entsetzt und bin mir mit meiner Maske...</td>\n",
       "      <td>Am Flughafen kam dann die Ernüchterung: \"Alle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91194</th>\n",
       "      <td>laz_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Landshuter Zeitung, 01.02.2020</td>\n",
       "      <td>Musik und Tanz ist angesagt und hierzu sind vi...</td>\n",
       "      <td>Masken sind also ausdrücklich erwünscht.</td>\n",
       "      <td>Für die musikalische Unterhaltung sorgt die G...</td>\n",
       "      <td>Musik und Tanz ist angesagt und hierzu sind vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91195</th>\n",
       "      <td>laz_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Landshuter Zeitung, 01.02.2020</td>\n",
       "      <td>Für das leibliche Wohl ist ebenfalls gesorgt.</td>\n",
       "      <td>Verkleidung und Masken sind erwünscht.</td>\n",
       "      <td></td>\n",
       "      <td>Für das leibliche Wohl ist ebenfalls gesorgt. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91196</th>\n",
       "      <td>ha_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Hamburger Abendblatt, 01.02.2020</td>\n",
       "      <td>\"Das Phantom der Oper\" kommt am Donnerstag, ...</td>\n",
       "      <td>Ab 20 Uhr wird die fesselnde Geschichte des en...</td>\n",
       "      <td>Er lebt tief in den Gewölben der Pariser Oper...</td>\n",
       "      <td>\"Das Phantom der Oper\" kommt am Donnerstag, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Corpus        Date    Genre                              Bibl  \\\n",
       "91192   sk_regional  2020-02-01  Zeitung             Südkurier, 01.02.2020   \n",
       "91193  mib_regional  2020-02-01  Zeitung      Mittelbayerische, 01.02.2020   \n",
       "91194  laz_regional  2020-02-01  Zeitung    Landshuter Zeitung, 01.02.2020   \n",
       "91195  laz_regional  2020-02-01  Zeitung    Landshuter Zeitung, 01.02.2020   \n",
       "91196   ha_regional  2020-02-01  Zeitung  Hamburger Abendblatt, 01.02.2020   \n",
       "\n",
       "                                           ContextBefore  \\\n",
       "91192    Gründungsmitglieder, die sogenannten Gelbjac...   \n",
       "91193           Am Flughafen kam dann die Ernüchterung:    \n",
       "91194  Musik und Tanz ist angesagt und hierzu sind vi...   \n",
       "91195     Für das leibliche Wohl ist ebenfalls gesorgt.    \n",
       "91196    \"Das Phantom der Oper\" kommt am Donnerstag, ...   \n",
       "\n",
       "                                                     Hit  \\\n",
       "91192  In ihrer Nachfolge gibt es seit 1993 die Gelbj...   \n",
       "91193   \"Alle tatschen dich an, keiner trägt eine Maske.   \n",
       "91194           Masken sind also ausdrücklich erwünscht.   \n",
       "91195             Verkleidung und Masken sind erwünscht.   \n",
       "91196  Ab 20 Uhr wird die fesselnde Geschichte des en...   \n",
       "\n",
       "                                            ContextAfter  \\\n",
       "91192                           Sie haben 33 Mitglieder.   \n",
       "91193   Ich war entsetzt und bin mir mit meiner Maske...   \n",
       "91194   Für die musikalische Unterhaltung sorgt die G...   \n",
       "91195                                                      \n",
       "91196   Er lebt tief in den Gewölben der Pariser Oper...   \n",
       "\n",
       "                                                    Text  \n",
       "91192    Gründungsmitglieder, die sogenannten Gelbjac...  \n",
       "91193  Am Flughafen kam dann die Ernüchterung: \"Alle ...  \n",
       "91194  Musik und Tanz ist angesagt und hierzu sind vi...  \n",
       "91195  Für das leibliche Wohl ist ebenfalls gesorgt. ...  \n",
       "91196    \"Das Phantom der Oper\" kommt am Donnerstag, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_corona.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hilfsfunktionen zur Vorbereitung der Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text_column(df, column):\n",
    "    \"\"\"\n",
    "    transforms the Dataframe-column in a lemmatized string\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        lemmas = ' '.join([x.lemma_ for x in doc])\n",
    "        text = text + lemmas\n",
    "    return text\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_äÄöÖüÜß]',' ', raw).split()                              \n",
    "    filtered_text = [word for word in text if word not in stopwords]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of tokenized sentences\n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    phrases = Phrases(tokenized_sentences)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = list(bigram[tokenized_sentences])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des ersten Texts (vor Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uVMUJzlpibZo",
    "outputId": "d9d2a45d-3e51-41e2-83a8-decaed115ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corona_bodyguard', 'uhr']\n"
     ]
    }
   ],
   "source": [
    "text = lemmatize_text_column(df_before_corona, 'Text')\n",
    "sentences = prepare_text(text)\n",
    "\n",
    "# sentences ist eine Liste von tokenisierten Sätzen, zum Beispiel:\n",
    "print(sentences[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des zweiten Texts (nach Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['top', 'stimmung_sorgen', 'zahlreiche', 'bunt', 'maske', 'aktivenabteilungen', 'lustig_einlage']\n"
     ]
    }
   ],
   "source": [
    "text2 = lemmatize_text_column(df_after_corona, 'Text')\n",
    "sentences2 = prepare_text(text2)\n",
    "\n",
    "print(sentences2[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training von Word2Vec auf den Text vor Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HI1V5EARibZo"
   },
   "outputs": [],
   "source": [
    "# Paramter setzen\n",
    "workers = 4                      # Use these many worker threads to train the model (=faster training with multicore machines)\n",
    "seed = 42                        # Seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gWLaiZ5cibZq"
   },
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kpbrlbf0ibZq",
    "outputId": "1f537e5c-add4-40c4-8b31-49c6f8869309"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "w2v_bc = Word2Vec(sentences=sentences,                   \n",
    "                 vector_size=300,          # Dimensionality of the word vectors\n",
    "                 window=10,                # The maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=3,              # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,         # Learning rate will linearly drop to min_alpha as training progresses\n",
    "                 sg=1,                     # Training algorithm: skip-gram if sg=1, otherwise CBOW\n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH8M_UkAibZr"
   },
   "source": [
    "## Training von Word2Vec auf den Text nach Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Gfy3LgWyibZt",
    "outputId": "0962a7be-cecd-4c1f-a1e0-ba52aff1fdc1"
   },
   "outputs": [],
   "source": [
    "w2v_ac = Word2Vec(sentences=sentences2,                   \n",
    "                 vector_size=300,                \n",
    "                 window=10,              \n",
    "                 min_count=3,             \n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,                                                    \n",
    "                 sg=1,                     \n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle speichern\n",
    "w2v_bc.save(os.path.join('../trained_models', 'w2v_bc_big.model'))\n",
    "w2v_ac.save(os.path.join('../trained_models', 'w2v_ac_big.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration und Vergleich der Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle laden\n",
    "w2v_bc = Word2Vec.load(os.path.join('../trained_models', 'w2v_bc_big.model'))\n",
    "w2v_ac = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_big.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "okTISay5ibZv",
    "outputId": "8f2fe288-c8ba-4abc-881f-a2ed7c6e69f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('querdenkern', 0.747796893119812),\n",
       " ('cdu', 0.7155287861824036),\n",
       " ('querdenkers', 0.7124019861221313),\n",
       " ('politisch', 0.7028190493583679),\n",
       " ('spd', 0.6653676629066467),\n",
       " ('partei', 0.656281054019928),\n",
       " ('kritisch', 0.5967330932617188),\n",
       " ('bezeichnen', 0.5948054194450378),\n",
       " ('politiker', 0.5935297012329102),\n",
       " ('professor', 0.5885156393051147),\n",
       " ('erfinder', 0.5733529329299927),\n",
       " ('autor', 0.5732239484786987),\n",
       " ('unbequem_querdenker', 0.5659780502319336),\n",
       " ('stadtrat', 0.5575906038284302),\n",
       " ('fdp', 0.5571948885917664),\n",
       " ('idee', 0.5541821718215942),\n",
       " ('kabarettist', 0.5500419735908508),\n",
       " ('gelten_querdenker', 0.5492470264434814),\n",
       " ('dichter', 0.5476680397987366),\n",
       " ('wissenschaftler', 0.5446919202804565)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['querdenker'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "twofLe79ibZw",
    "outputId": "baea5bc0-fcdb-4e83-c22c-37853c505e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('querdenkern', 0.7541735172271729),\n",
       " ('leugner', 0.71431565284729),\n",
       " ('querdenken', 0.711727499961853),\n",
       " ('rechtsextremisten', 0.687041699886322),\n",
       " ('sogenannt_querdenker', 0.681483268737793),\n",
       " ('rechtsextreme', 0.680782675743103),\n",
       " ('impfgegner', 0.6660829186439514),\n",
       " ('reichsbürgern', 0.6636567115783691),\n",
       " ('reichsbürger', 0.6634799242019653),\n",
       " ('bodo_schiffmann', 0.657234251499176),\n",
       " ('gegendemonstranten', 0.6558753848075867),\n",
       " ('protest', 0.6537598371505737),\n",
       " ('ernannt_querdenker', 0.6517921090126038),\n",
       " ('demonstration', 0.6482175588607788),\n",
       " ('sogenannt_querdenkern', 0.6453119516372681),\n",
       " ('verfassungsschutz', 0.645193338394165),\n",
       " ('demonstrant', 0.6378492712974548),\n",
       " ('demo', 0.6361711025238037),\n",
       " ('verschwörungstheoretiker', 0.6360674500465393),\n",
       " ('querdenker_bewegung', 0.6336623430252075)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['querdenker'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('corona_kino', 0.6190341114997864),\n",
       " ('center_telefon', 0.5996342301368713),\n",
       " ('the_pipebag', 0.5187975168228149),\n",
       " ('jungs', 0.5073242783546448),\n",
       " ('king', 0.5063794255256653),\n",
       " ('hotel_post', 0.48166266083717346),\n",
       " ('sergio_corona', 0.4798022508621216),\n",
       " ('uhr_diamantencop', 0.47882843017578125),\n",
       " ('millau_kritiker', 0.47573453187942505),\n",
       " ('links_gault', 0.4756649136543274),\n",
       " ('gastgeber_sergio', 0.4750829339027405),\n",
       " ('james_bond', 0.4741738438606262),\n",
       " ('uhr_american', 0.4670339822769165),\n",
       " ('uhr_faculty', 0.46575549244880676),\n",
       " ('sorte', 0.464731365442276),\n",
       " ('hardert', 0.46293747425079346),\n",
       " ('uhr_rush', 0.46027684211730957),\n",
       " ('diesmal_kochkunst', 0.45990481972694397),\n",
       " ('the', 0.45820873975753784),\n",
       " ('uhr_end', 0.45151638984680176)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'corona' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['corona'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gem', 0.6111908555030823),\n",
       " ('weitder', 0.5885581970214844),\n",
       " ('nahezu_vollständig', 0.5855190753936768),\n",
       " ('früherkennung', 0.5840460658073425),\n",
       " ('ungewisse', 0.582464873790741),\n",
       " ('schwimmausbildung', 0.5787183046340942),\n",
       " ('tder', 0.5758451223373413),\n",
       " ('nordwestkreis', 0.5743584036827087),\n",
       " ('völlig_erliegen', 0.5732845664024353),\n",
       " ('pfingsturlaub', 0.5723441243171692),\n",
       " ('eingeleitet', 0.5665045380592346),\n",
       " ('aderlass', 0.5663558840751648),\n",
       " ('coronader', 0.5661740303039551),\n",
       " ('großraum_münchen', 0.5659241080284119),\n",
       " ('theatersommer', 0.5658591389656067),\n",
       " ('mitcorona', 0.5646794438362122),\n",
       " ('zitat_text', 0.5636439919471741),\n",
       " ('stefan_heimpel', 0.5629909634590149),\n",
       " ('verlautbarung', 0.5627800822257996),\n",
       " ('stader', 0.5624494552612305)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'corona' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['corona'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('füßlinge', 0.5193455815315247),\n",
       " ('vollmasken', 0.5010046362876892),\n",
       " ('stammen_manfred', 0.495825856924057),\n",
       " ('schwarz_weiße', 0.49447399377822876),\n",
       " ('masken', 0.49355924129486084),\n",
       " ('rebstock', 0.4916764795780182),\n",
       " ('überjacke', 0.4913744330406189),\n",
       " ('mehl', 0.4908754527568817),\n",
       " ('kleid', 0.4898667633533478),\n",
       " ('reichenbach', 0.4872777462005615),\n",
       " ('verkleidungsgegenständen', 0.48669159412384033),\n",
       " ('enthalten_oft', 0.48575690388679504),\n",
       " ('furchterregenden', 0.4856216013431549),\n",
       " ('gepolstert', 0.4854210615158081),\n",
       " ('kopfbedeckung', 0.4849424958229065),\n",
       " ('urwüchsige', 0.4848916232585907),\n",
       " ('handschuh', 0.4846534729003906),\n",
       " ('eltern_nachwuchs', 0.48456692695617676),\n",
       " ('roten', 0.4845435321331024),\n",
       " ('schädliche_weichmacher', 0.4840468764305115)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'maske' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['maske'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('schutzmaske', 0.6495651006698608),\n",
       " ('mund_nasenbedeckung', 0.6437532305717468),\n",
       " ('gesichtsmaske', 0.6189560294151306),\n",
       " ('gesichtsmasken', 0.6133692860603333),\n",
       " ('tuch', 0.6128157377243042),\n",
       " ('markierung_boden', 0.6064082980155945),\n",
       " ('maske_aufziehen', 0.6053450107574463),\n",
       " ('auge_stirn', 0.6050472259521484),\n",
       " ('nase_mund', 0.6035911440849304),\n",
       " ('aufliegen', 0.5963257551193237),\n",
       " ('mund_bedecken', 0.5960667133331299),\n",
       " ('seife_waschen', 0.5959150791168213),\n",
       " ('nasenschutz', 0.5951909422874451),\n",
       " ('alltagsmasken', 0.595059871673584),\n",
       " ('tuch_schal', 0.5935741662979126),\n",
       " ('gehören_alltag', 0.5922637581825256),\n",
       " ('coronaschutz', 0.5914943814277649),\n",
       " ('bedeckung_mund', 0.5913928747177124),\n",
       " ('fabrik_eingangs', 0.5913369655609131),\n",
       " ('atemschutzmaske', 0.5907206535339355)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'maske' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['maske'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kontaktverbote', 0.8487755060195923),\n",
       " ('angeklagte', 0.8438047170639038),\n",
       " ('gericht', 0.8409157395362854),\n",
       " ('verhängen', 0.8370905518531799),\n",
       " ('aussprechen', 0.8322799205780029),\n",
       " ('erwirken', 0.8251029253005981),\n",
       " ('auflage', 0.8222008943557739),\n",
       " ('kontaktverbots', 0.8211990594863892),\n",
       " ('gerichtlich', 0.8203415870666504),\n",
       " ('körperverletzung', 0.8088024258613586),\n",
       " ('staatsanwaltschaft', 0.8074296116828918),\n",
       " ('verstoßen', 0.803770124912262),\n",
       " ('haft', 0.8007863759994507),\n",
       " ('vergewaltigung', 0.80012446641922),\n",
       " ('verurteilen', 0.7986146211624146),\n",
       " ('amtsgericht', 0.7960127592086792),\n",
       " ('erteilen', 0.7917131185531616),\n",
       " ('kontaktverbot_gewaltschutzgesetz', 0.790230393409729),\n",
       " ('beantragen', 0.7899919152259827),\n",
       " ('gerichtlich_kontaktverbot', 0.7892284989356995)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'kontaktverbot' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['kontaktverbot'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kontaktverbote', 0.6860386729240417),\n",
       " ('kontaktverbots', 0.6290916800498962),\n",
       " ('erwirken', 0.627249002456665),\n",
       " ('familiengericht', 0.5953232049942017),\n",
       " ('karlheinz_r', 0.5874902009963989),\n",
       " ('kontaktverbotes', 0.5872052311897278),\n",
       " ('verhängen', 0.5793020725250244),\n",
       " ('ausgangssperre', 0.5755935311317444),\n",
       " ('ausgangsbeschränkungen', 0.5641852021217346),\n",
       " ('kontaktverbot_verhängen', 0.5638619065284729),\n",
       " ('richterlich', 0.5601125955581665),\n",
       " ('ja_irgendeine', 0.5570877194404602),\n",
       " ('ex_freundin', 0.5521845817565918),\n",
       " ('herrschen_strikt', 0.5432443618774414),\n",
       " ('landesregierung_weitreichend', 0.542468249797821),\n",
       " ('strikte', 0.5416397452354431),\n",
       " ('kontaktverboten', 0.5401198863983154),\n",
       " ('einreiseverbot', 0.5371778011322021),\n",
       " ('ausgangsbeschränkung', 0.5358422994613647),\n",
       " ('versammlungs', 0.5321037769317627)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'kontaktverbot' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['kontaktverbot'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('befürchten', 0.924042284488678),\n",
       " ('betroffene', 0.9178076982498169),\n",
       " ('atemnot', 0.9123352766036987),\n",
       " ('mild', 0.9087622165679932),\n",
       " ('strafbar', 0.9059414267539978),\n",
       " ('verordnen', 0.9059011936187744),\n",
       " ('anschlag', 0.9032668471336365),\n",
       " ('anprangern', 0.9017435908317566),\n",
       " ('gefahrlos', 0.900870680809021),\n",
       " ('schlafstörungen', 0.8990635275840759),\n",
       " ('angehörige', 0.897489607334137),\n",
       " ('sofortig', 0.8940799832344055),\n",
       " ('beseitigen', 0.8910394310951233),\n",
       " ('sinnlos', 0.8905192613601685),\n",
       " ('panik', 0.890012800693512),\n",
       " ('überzeugung', 0.8889331817626953),\n",
       " ('auswertung', 0.8889322280883789),\n",
       " ('unfall', 0.8885056376457214),\n",
       " ('verweigern', 0.8877385854721069),\n",
       " ('hure', 0.8870447874069214)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'virus' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['virus'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coronavirus', 0.5161033868789673),\n",
       " ('krise_leisten', 0.5033251047134399),\n",
       " ('bamberger_computer', 0.5025117993354797),\n",
       " ('zelle', 0.49827510118484497),\n",
       " ('ausbreitung', 0.4973306357860565),\n",
       " ('entwickler_ih', 0.4937213361263275),\n",
       " ('ihder', 0.48669472336769104),\n",
       " ('sars_cov', 0.48655927181243896),\n",
       " ('covid', 0.4811962842941284),\n",
       " ('entwickler', 0.4784873127937317),\n",
       " ('erreger', 0.4750414192676544),\n",
       " ('computergestützte_ortung', 0.47340935468673706),\n",
       " ('lebenswichtig_lieferung', 0.47162145376205444),\n",
       " ('epidemie', 0.46914738416671753),\n",
       " ('hilfesuchend_verbinden', 0.46714064478874207),\n",
       " ('ihein', 0.4655172526836395),\n",
       " ('reale_helfer', 0.4652503728866577),\n",
       " ('virtuelle_apps', 0.4635000228881836),\n",
       " ('digital_unterricht', 0.46136701107025146),\n",
       " ('eindringen', 0.4608757793903351)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'virus' vor Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['virus'], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausrichtung der beiden Embedding-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Updatet script: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "    Procrustes align two gensim models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
    "    # base_embed.init_sims(replace=True)\n",
    "    # other_embed.init_sims(replace=True)\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "    \n",
    "    # re-filling the normed vectors\n",
    "    in_base_embed.wv.fill_norms(force=True)\n",
    "    in_other_embed.wv.fill_norms(force=True)\n",
    "\n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n",
    "\n",
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29563 29563\n",
      "29563 29563\n"
     ]
    }
   ],
   "source": [
    "# Ausrichtung des \"After-Corona-Modells\" an das \"Before-Corona-Modell\"\n",
    "\n",
    "w2v_ac_al = smart_procrustes_align_gensim(w2v_bc, w2v_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern\n",
    "w2v_ac_al.save(os.path.join('../trained_models', 'w2v_ac_al_big.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus-Ähnlichkeit zwischen den Vektoren der beiden Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laden\n",
    "w2v_ac_al = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_al_big.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('querdenkern', 0.7541735172271729),\n",
       " ('querdenken', 0.7117274403572083),\n",
       " ('rechtsextremisten', 0.687041699886322),\n",
       " ('rechtsextreme', 0.6807827949523926),\n",
       " ('protest', 0.6537598967552185),\n",
       " ('demonstration', 0.6482175588607788),\n",
       " ('verfassungsschutz', 0.6451934576034546),\n",
       " ('demonstrant', 0.6378492712974548),\n",
       " ('demo', 0.6361710429191589),\n",
       " ('kundgebung', 0.6321370601654053),\n",
       " ('demonstranten', 0.623324990272522),\n",
       " ('nazi', 0.6222254633903503),\n",
       " ('kritiker', 0.6215149164199829),\n",
       " ('aufmarsch', 0.6212500333786011),\n",
       " ('neonazi', 0.6188969612121582),\n",
       " ('kassel', 0.6185775399208069),\n",
       " ('rebell', 0.6153010725975037),\n",
       " ('protestieren', 0.6134769320487976),\n",
       " ('querulant', 0.6130459904670715),\n",
       " ('rechtsextrem', 0.6095647811889648),\n",
       " ('distanzieren', 0.605800986289978),\n",
       " ('demonstrieren', 0.5999816060066223),\n",
       " ('augustusplatz', 0.5995814204216003),\n",
       " ('rechtsradikale', 0.5974807739257812),\n",
       " ('antifa', 0.5954942107200623)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' nach Covid-19\n",
    "w2v_ac_al.wv.most_similar(positive=['querdenker'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5813612341880798"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_querdenker_bc = w2v_bc.wv['querdenker']  \n",
    "vector_querdenker_ac_al = w2v_ac_al.wv['querdenker'] \n",
    "\n",
    "cosine_querdenker = 1 - spatial.distance.cosine(vector_querdenker_bc, vector_querdenker_ac_al)\n",
    "cosine_querdenker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7160080075263977"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_maske_bc = w2v_bc.wv['maske']  \n",
    "vector_maske_ac_al = w2v_ac_al.wv['maske'] \n",
    "\n",
    "cosine_maske = 1 - spatial.distance.cosine(vector_maske_bc, vector_maske_ac_al)\n",
    "cosine_maske"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625801682472229"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_kontaktverbot_bc = w2v_bc.wv['kontaktverbot']  \n",
    "vector_kontaktverbot_ac_al = w2v_ac_al.wv['kontaktverbot'] \n",
    "\n",
    "cosine_kontaktverbot = 1 - spatial.distance.cosine(vector_kontaktverbot_bc, vector_kontaktverbot_ac_al)\n",
    "cosine_kontaktverbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3815651535987854"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_corona_bc = w2v_bc.wv['corona']  \n",
    "vector_corona_ac_al = w2v_ac_al.wv['corona'] \n",
    "\n",
    "cosine_corona = 1 - spatial.distance.cosine(vector_corona_bc, vector_corona_ac_al)\n",
    "cosine_corona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48214223980903625"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versuch mit unverfänglichen Wörtern\n",
    "\n",
    "vector_deutschland_bc = w2v_bc.wv['deutschland']  \n",
    "vector_deutschland_ac_al = w2v_ac_al.wv['deutschland'] \n",
    "\n",
    "cosine_deutschland = 1 - spatial.distance.cosine(vector_deutschland_bc, vector_deutschland_ac_al)\n",
    "cosine_deutschland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36761733889579773"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_nachricht_bc = w2v_bc.wv['nachricht']  \n",
    "vector_nachricht_ac_al = w2v_ac_al.wv['nachricht'] \n",
    "\n",
    "cosine_nachricht = 1 - spatial.distance.cosine(vector_nachricht_bc, vector_nachricht_ac_al)\n",
    "cosine_nachricht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4688681662082672"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_schreiben_bc = w2v_bc.wv['schreiben']  \n",
    "vector_schreiben_ac_al = w2v_ac_al.wv['schreiben'] \n",
    "\n",
    "cosine_schreiben = 1 - spatial.distance.cosine(vector_schreiben_bc, vector_schreiben_ac_al)\n",
    "cosine_schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6580893993377686"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_sagen_bc = w2v_bc.wv['sagen']  \n",
    "vector_sagen_ac_al = w2v_ac_al.wv['sagen'] \n",
    "\n",
    "cosine_sagen = 1 - spatial.distance.cosine(vector_sagen_bc, vector_sagen_ac_al)\n",
    "cosine_sagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760576605796814"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mann_bc = w2v_bc.wv['mann']  \n",
    "vector_mann_ac_al = w2v_ac_al.wv['mann'] \n",
    "\n",
    "cosine_mann = 1 - spatial.distance.cosine(vector_mann_bc, vector_mann_ac_al)\n",
    "cosine_mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6710892915725708"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_frau_bc = w2v_bc.wv['frau']  \n",
    "vector_frau_ac_al = w2v_ac_al.wv['frau'] \n",
    "\n",
    "cosine_frau = 1 - spatial.distance.cosine(vector_frau_bc, vector_frau_ac_al)\n",
    "cosine_frau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652454733848572"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mensch_bc = w2v_bc.wv['mensch']  \n",
    "vector_mensch_ac_al = w2v_ac_al.wv['mensch'] \n",
    "\n",
    "cosine_mensch = 1 - spatial.distance.cosine(vector_mensch_bc, vector_mensch_ac_al)\n",
    "cosine_mensch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5274260640144348"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_montag_bc = w2v_bc.wv['montag']  \n",
    "vector_montag_ac_al = w2v_ac_al.wv['montag'] \n",
    "\n",
    "cosine_montag = 1 - spatial.distance.cosine(vector_montag_bc, vector_montag_ac_al)\n",
    "cosine_montag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### durchschnittliche Cosinus-Ähnlichkeit, Standardweichung und 'Normalbereich'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- von allen Wörtern/Vektoren, die in beiden Modellen vorkommen jeweils die Cosinus-Ähnlichkeit berechnen (also zueinander zwischen den Modellen)\n",
    "- durchschnittliche Ähnlichkeit und Standardabweichung berechnen, um einen 'Normalbereich' zu ermitteln\n",
    "- liegt der Wert der Cosinus-Ähnlichkeit (desselben Lemmas zwischen den Modellen) unter dem Normalbereich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle Wörter, die in beiden Modellen vorkommmen\n",
    "\n",
    "vocab_bc = set(w2v_bc.wv.index_to_key)\n",
    "vocab_ac_al = set(w2v_ac_al.wv.index_to_key)\n",
    "\n",
    "common_vocab = vocab_bc & vocab_ac_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29563"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosinus-Ähnlichkeit zwischen dem Wort in den beiden Modellen berechnen\n",
    "\n",
    "cosines = {}\n",
    "\n",
    "for word in common_vocab:\n",
    "    vector_bc = w2v_bc.wv[word]  \n",
    "    vector_ac_al = w2v_ac_al.wv[word] \n",
    "    cosine = 1 - spatial.distance.cosine(vector_bc, vector_ac_al)\n",
    "    cosines[word] = cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mainburg</th>\n",
       "      <td>0.595286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weiterführend</th>\n",
       "      <td>0.710035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sax</th>\n",
       "      <td>0.843582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winterlich</th>\n",
       "      <td>0.839954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mui</th>\n",
       "      <td>0.707011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isselhorster</th>\n",
       "      <td>0.839153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shows</th>\n",
       "      <td>0.744817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratsherr</th>\n",
       "      <td>0.817874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kenner</th>\n",
       "      <td>0.803671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svo</th>\n",
       "      <td>0.820596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29563 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cosine\n",
       "mainburg       0.595286\n",
       "weiterführend  0.710035\n",
       "sax            0.843582\n",
       "winterlich     0.839954\n",
       "mui            0.707011\n",
       "...                 ...\n",
       "isselhorster   0.839153\n",
       "shows          0.744817\n",
       "ratsherr       0.817874\n",
       "kenner         0.803671\n",
       "svo            0.820596\n",
       "\n",
       "[29563 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df = pd.DataFrame.from_dict(cosines, orient='index', columns=['cosine'])\n",
    "cosine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666604625206636"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# durchschnittliche Cosinus-Ähnlichkeit der Wörter der beiden Modelle \n",
    "\n",
    "statistics.mean(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11899796052473466"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardabweichung\n",
    "\n",
    "statistics.stdev(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Normalbereich der Cosinus-Ähnlichkeit liegt über 0.6476625019959289\n"
     ]
    }
   ],
   "source": [
    "# 'Normalbereich' der Cosinus-Ähnlichkeit\n",
    "\n",
    "border = statistics.mean(cosine_df['cosine']) - statistics.stdev(cosine_df['cosine'])\n",
    "\n",
    "print('der Normalbereich der Cosinus-Ähnlichkeit liegt über', border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>u_geschw</th>\n",
       "      <td>0.088831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zulässt</th>\n",
       "      <td>0.253461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kv</th>\n",
       "      <td>0.281852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alten_pflegeheim</th>\n",
       "      <td>0.287196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers</th>\n",
       "      <td>0.287475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regeln</th>\n",
       "      <td>0.288149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erst_recht</th>\n",
       "      <td>0.288547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strich</th>\n",
       "      <td>0.294452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opfer</th>\n",
       "      <td>0.294633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trotz</th>\n",
       "      <td>0.300348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positiv</th>\n",
       "      <td>0.301721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.306349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neunkirchen</th>\n",
       "      <td>0.310561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eck</th>\n",
       "      <td>0.310651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.317838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raiffeisenbank</th>\n",
       "      <td>0.320958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trotzen</th>\n",
       "      <td>0.322265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lahm</th>\n",
       "      <td>0.325644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haupt</th>\n",
       "      <td>0.327920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>streichen</th>\n",
       "      <td>0.330590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fassung</th>\n",
       "      <td>0.331761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geschwindigkeit</th>\n",
       "      <td>0.332245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstand</th>\n",
       "      <td>0.338397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lage</th>\n",
       "      <td>0.340270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>einzelhandel</th>\n",
       "      <td>0.340581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwingen</th>\n",
       "      <td>0.342831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ansage</th>\n",
       "      <td>0.343449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>0.343915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>letzt_tag</th>\n",
       "      <td>0.348060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absagen</th>\n",
       "      <td>0.349072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    cosine\n",
       "u_geschw          0.088831\n",
       "zulässt           0.253461\n",
       "kv                0.281852\n",
       "alten_pflegeheim  0.287196\n",
       "pers              0.287475\n",
       "regeln            0.288149\n",
       "erst_recht        0.288547\n",
       "strich            0.294452\n",
       "opfer             0.294633\n",
       "trotz             0.300348\n",
       "positiv           0.301721\n",
       "fr                0.306349\n",
       "neunkirchen       0.310561\n",
       "eck               0.310651\n",
       "z                 0.317838\n",
       "raiffeisenbank    0.320958\n",
       "trotzen           0.322265\n",
       "lahm              0.325644\n",
       "haupt             0.327920\n",
       "streichen         0.330590\n",
       "fassung           0.331761\n",
       "geschwindigkeit   0.332245\n",
       "abstand           0.338397\n",
       "lage              0.340270\n",
       "einzelhandel      0.340581\n",
       "zwingen           0.342831\n",
       "ansage            0.343449\n",
       "it                0.343915\n",
       "letzt_tag         0.348060\n",
       "absagen           0.349072"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardabweichung erscheint hoch\n",
    "# DF aufsteigend sortieren und die ersten 30 Zeilen ausgeben, um die 'Ausreißer' anzuschauen\n",
    "\n",
    "cosine_df.sort_values(by=['cosine'], axis=0).iloc[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Versuch: Ausreißer (hier mal alle unter 0,3) rauslöschen und erneut den Normalbereich berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trotz</th>\n",
       "      <td>0.300348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positiv</th>\n",
       "      <td>0.301721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.306349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neunkirchen</th>\n",
       "      <td>0.310561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eck</th>\n",
       "      <td>0.310651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cosine\n",
       "trotz        0.300348\n",
       "positiv      0.301721\n",
       "fr           0.306349\n",
       "neunkirchen  0.310561\n",
       "eck          0.310651"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df_new = cosine_df.sort_values(by=['cosine'], axis=0).iloc[9:,:]\n",
    "cosine_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7668139222406071"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(cosine_df_new['cosine']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11868561759126793"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.stdev(cosine_df_new['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Normalbereich der Cosinus-Ähnlichkeit liegt über 0.6481283046493391\n"
     ]
    }
   ],
   "source": [
    "# neuer 'Normalbereich' der Cosinus-Ähnlichkeit\n",
    "\n",
    "border = statistics.mean(cosine_df_new['cosine']) - statistics.stdev(cosine_df_new['cosine'])\n",
    "\n",
    "print('der Normalbereich der Cosinus-Ähnlichkeit liegt über', border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_querdenker < border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_maske < border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_corona < border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_kontaktverbot < border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Cosinus-Ähnlichkeit zwischen den Vektoren 'Querdenker', 'Corona' und 'Kontaktverbot' liegt jeweils unterhalb des Normalbereichs. <br>\n",
    "Die Hypothese kann für diese Lemmas als verifiziert gelten. <br>\n",
    "Die Cosinus-Ähnlichkeit zwischen den Vektoren 'Maske' liegt zwar unterhlab des Durchschnitts, jedoch noch im Normalbereich. <br>      \n",
    "Die Hypothese ist für dieses Lemmas nicht verifiziert. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideen für weitere Wörter: Abstandsregel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiteres Vorgehen:\n",
    "- Korpora shuffeln und random in 2 teilen\n",
    "- erneut trainieren, angleichen und Cosinus berechnen\n",
    "- der Cosinus zwischen Querdenker und Querdenker müsste jetzt größer sein als hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext Corona.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
