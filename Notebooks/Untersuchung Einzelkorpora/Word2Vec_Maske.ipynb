{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq24UvixibZR"
   },
   "source": [
    "# 'Maske' vor und nach Covid-19 - eine Untersuchung mit Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bedeutungen des Lemmas 'Maske'\n",
    "\n",
    "1. künstliche feste Hülle vor dem Gesicht, Larve <br>\n",
    "[bildlich] ... <br>\n",
    "Deckmantel\n",
    "2. Kostümierung, besonders das geschminkte Gesicht des Schauspielers\n",
    "3. Träger von 1, Vermummte, Vermummter, Verkleidete, Verkleideter <br>\n",
    "(Quelle: https://www.dwds.de/wb/Maske) <br> \n",
    "<br> \n",
    "\n",
    "#### Hypothese\n",
    "\n",
    "Durch die Pandemie und die damit einhergehende Notwendigkeit von Seuchenschutzmaßnahmen gewinnt die Lesart 1), und dabei insbesondere die Bedeutung von Maske als Mund-Nasen-Schutz, an Popularität und verdrängt die anderen Bedeutungen. Die Bedeutung des Lemmas wandelt sich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FQnxIrfibZf"
   },
   "source": [
    "## Importe und Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIZS463EibZh",
    "outputId": "d8d8fe3f-70be-4322-a081-ba1b02ef7f2f"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjlyp7Bjiu60",
    "outputId": "83b51d0b-4222-48c0-ecb3-a6a2d926c0ae"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "stopwords = stopwords.words('german')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus laden und teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "QaI8RPMJibZj",
    "outputId": "7a4e7af2-20e5-4048-a2b1-341f8c0a8568"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer Tr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-06</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 06.02.1993</td>\n",
       "      <td>[...] Opfer einer Serie von Vergewaltigungen z...</td>\n",
       "      <td>Der Mann mit der Maske ließ ab und flüchtete.</td>\n",
       "      <td>Der 23jährige Skinhead Markus L. hatte vor wen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-10</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 10.02.1993</td>\n",
       "      <td>[...] gibt 's ka Sünd \", worauf auch die Dekor...</td>\n",
       "      <td>Die schönsten Kostüme und Masken werden mit be...</td>\n",
       "      <td>Zum Tanz spielt die \"happy music\" auf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-10</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 10.02.1993</td>\n",
       "      <td>[...]tiven, im besonderen an den Spätzündervor...</td>\n",
       "      <td>In bewährter Manier zeichneten verantwortlich,...</td>\n",
       "      <td>Als flitzender Butler fungierte Christian Klesen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-11</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 11.02.1993</td>\n",
       "      <td>[...]n und verließ fluchtartig die Schalterhalle.</td>\n",
       "      <td>Beim Verlassen der Poststelle in der Wadgasser...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "1  saar_regional  1993-02-06  Zeitung  Saarbrücker Zeitung, 06.02.1993   \n",
       "2  saar_regional  1993-02-10  Zeitung  Saarbrücker Zeitung, 10.02.1993   \n",
       "3  saar_regional  1993-02-10  Zeitung  Saarbrücker Zeitung, 10.02.1993   \n",
       "4  saar_regional  1993-02-11  Zeitung  Saarbrücker Zeitung, 11.02.1993   \n",
       "\n",
       "                                       ContextBefore  \\\n",
       "0                                                NaN   \n",
       "1  [...] Opfer einer Serie von Vergewaltigungen z...   \n",
       "2  [...] gibt 's ka Sünd \", worauf auch die Dekor...   \n",
       "3  [...]tiven, im besonderen an den Spätzündervor...   \n",
       "4  [...]n und verließ fluchtartig die Schalterhalle.   \n",
       "\n",
       "                                                 Hit  \\\n",
       "0  Von der farbkräftigen Maske (Venezianischer Tr...   \n",
       "1      Der Mann mit der Maske ließ ab und flüchtete.   \n",
       "2  Die schönsten Kostüme und Masken werden mit be...   \n",
       "3  In bewährter Manier zeichneten verantwortlich,...   \n",
       "4  Beim Verlassen der Poststelle in der Wadgasser...   \n",
       "\n",
       "                                        ContextAfter  \n",
       "0                                                NaN  \n",
       "1  Der 23jährige Skinhead Markus L. hatte vor wen...  \n",
       "2             Zum Tanz spielt die \"happy music\" auf.  \n",
       "3  Als flitzender Butler fungierte Christian Klesen.  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# die Datei enthält alle Treffer des Lemmas 'maske' im ZDL-Regionalkorpus des DWDS \n",
    "# mit jeweils einem Satz Kontext davor und danach\n",
    "\n",
    "df = pd.read_csv('../data/maske_1993-2021.csv', sep=',', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN durch Whitespace ersetzen\n",
    "\n",
    "df = df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wörter, die mit [...] anfangen löschen\n",
    "\n",
    "expression = '\\[...]\\w*'\n",
    "df = df.replace(to_replace = expression, value = ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bevor die Spalten verbunden werden: Whitespace einfügen, um ein Aneinanderkleben der Wörter zu verhindern\n",
    "\n",
    "df['ContextBefore'] = df['ContextBefore'].astype(str) + ' '\n",
    "df['ContextAfter'] = ' ' + df['ContextAfter'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 01.02.1993</td>\n",
       "      <td></td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer Tr...</td>\n",
       "      <td></td>\n",
       "      <td>Von der farbkräftigen Maske (Venezianischer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-06</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 06.02.1993</td>\n",
       "      <td>Opfer einer Serie von Vergewaltigungen zu we...</td>\n",
       "      <td>Der Mann mit der Maske ließ ab und flüchtete.</td>\n",
       "      <td>Der 23jährige Skinhead Markus L. hatte vor we...</td>\n",
       "      <td>Opfer einer Serie von Vergewaltigungen zu we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-10</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 10.02.1993</td>\n",
       "      <td>gibt 's ka Sünd \", worauf auch die Dekoratio...</td>\n",
       "      <td>Die schönsten Kostüme und Masken werden mit be...</td>\n",
       "      <td>Zum Tanz spielt die \"happy music\" auf.</td>\n",
       "      <td>gibt 's ka Sünd \", worauf auch die Dekoratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-10</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 10.02.1993</td>\n",
       "      <td>, im besonderen an den Spätzündervorsitzenden...</td>\n",
       "      <td>In bewährter Manier zeichneten verantwortlich,...</td>\n",
       "      <td>Als flitzender Butler fungierte Christian Kle...</td>\n",
       "      <td>, im besonderen an den Spätzündervorsitzenden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-02-11</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 11.02.1993</td>\n",
       "      <td>und verließ fluchtartig die Schalterhalle.</td>\n",
       "      <td>Beim Verlassen der Poststelle in der Wadgasser...</td>\n",
       "      <td></td>\n",
       "      <td>und verließ fluchtartig die Schalterhalle. B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-02-01  Zeitung  Saarbrücker Zeitung, 01.02.1993   \n",
       "1  saar_regional  1993-02-06  Zeitung  Saarbrücker Zeitung, 06.02.1993   \n",
       "2  saar_regional  1993-02-10  Zeitung  Saarbrücker Zeitung, 10.02.1993   \n",
       "3  saar_regional  1993-02-10  Zeitung  Saarbrücker Zeitung, 10.02.1993   \n",
       "4  saar_regional  1993-02-11  Zeitung  Saarbrücker Zeitung, 11.02.1993   \n",
       "\n",
       "                                       ContextBefore  \\\n",
       "0                                                      \n",
       "1    Opfer einer Serie von Vergewaltigungen zu we...   \n",
       "2    gibt 's ka Sünd \", worauf auch die Dekoratio...   \n",
       "3   , im besonderen an den Spätzündervorsitzenden...   \n",
       "4        und verließ fluchtartig die Schalterhalle.    \n",
       "\n",
       "                                                 Hit  \\\n",
       "0  Von der farbkräftigen Maske (Venezianischer Tr...   \n",
       "1      Der Mann mit der Maske ließ ab und flüchtete.   \n",
       "2  Die schönsten Kostüme und Masken werden mit be...   \n",
       "3  In bewährter Manier zeichneten verantwortlich,...   \n",
       "4  Beim Verlassen der Poststelle in der Wadgasser...   \n",
       "\n",
       "                                        ContextAfter  \\\n",
       "0                                                      \n",
       "1   Der 23jährige Skinhead Markus L. hatte vor we...   \n",
       "2             Zum Tanz spielt die \"happy music\" auf.   \n",
       "3   Als flitzender Butler fungierte Christian Kle...   \n",
       "4                                                      \n",
       "\n",
       "                                                Text  \n",
       "0    Von der farbkräftigen Maske (Venezianischer ...  \n",
       "1    Opfer einer Serie von Vergewaltigungen zu we...  \n",
       "2    gibt 's ka Sünd \", worauf auch die Dekoratio...  \n",
       "3   , im besonderen an den Spätzündervorsitzenden...  \n",
       "4    und verließ fluchtartig die Schalterhalle. B...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text zu einer Spalte verbinden\n",
    "\n",
    "columns = ['ContextBefore', 'Hit', 'ContextAfter']\n",
    "\n",
    "df['Text'] = df[columns].astype(str).sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154567, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6uioii_SibZl"
   },
   "outputs": [],
   "source": [
    "# Korpus in 2 Teilkorpora splitten: vor und nach Covid-19 (dem Ausbruch in Deutschland)\n",
    "# hier wurde die Grenze zwischen Januar und Februar 2020 gezogen (es wird sich noch zeigen, inwiefern sich das bewährt)\n",
    "\n",
    "df_before_corona = df.iloc[:75633,:]\n",
    "df_after_corona = df.iloc[75634:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75634</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2020</td>\n",
       "      <td>, sondern beim Strählen in den Neudinger Gast...</td>\n",
       "      <td>Beim Strählen wird das Gesicht mit einer Maske...</td>\n",
       "      <td>Die ersten Narreblättli-Ausgaben, die heute n...</td>\n",
       "      <td>, sondern beim Strählen in den Neudinger Gast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75635</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2020</td>\n",
       "      <td>Gründungsmitglieder, die sogenannten Gelbjac...</td>\n",
       "      <td>In ihrer Nachfolge gibt es seit 1993 die Gelbj...</td>\n",
       "      <td>Sie haben 33 Mitglieder.</td>\n",
       "      <td>Gründungsmitglieder, die sogenannten Gelbjac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75636</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2020</td>\n",
       "      <td>Sie haben 33 Mitglieder.</td>\n",
       "      <td>Neue Cliquen: 1970 wurden die Erzgräber (33 Mi...</td>\n",
       "      <td>Die 1971 gegründete Gruppierung der Hexen wur...</td>\n",
       "      <td>Sie haben 33 Mitglieder. Neue Cliquen: 1970 wu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2020</td>\n",
       "      <td>einzelnen Zünften wurden gesammelt und eine ...</td>\n",
       "      <td>Ein Häs mit den Konterfeis aller Masken und Ut...</td>\n",
       "      <td>Es blieb nicht beim Häs für den Rathauschef, ...</td>\n",
       "      <td>einzelnen Zünften wurden gesammelt und eine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75638</th>\n",
       "      <td>sk_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Südkurier, 01.02.2020</td>\n",
       "      <td></td>\n",
       "      <td>Die Zunftstube im Haus Mariagrün im Westen der...</td>\n",
       "      <td></td>\n",
       "      <td>Die Zunftstube im Haus Mariagrün im Westen d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Corpus        Date    Genre                   Bibl  \\\n",
       "75634  sk_regional  2020-02-01  Zeitung  Südkurier, 01.02.2020   \n",
       "75635  sk_regional  2020-02-01  Zeitung  Südkurier, 01.02.2020   \n",
       "75636  sk_regional  2020-02-01  Zeitung  Südkurier, 01.02.2020   \n",
       "75637  sk_regional  2020-02-01  Zeitung  Südkurier, 01.02.2020   \n",
       "75638  sk_regional  2020-02-01  Zeitung  Südkurier, 01.02.2020   \n",
       "\n",
       "                                           ContextBefore  \\\n",
       "75634   , sondern beim Strählen in den Neudinger Gast...   \n",
       "75635    Gründungsmitglieder, die sogenannten Gelbjac...   \n",
       "75636                          Sie haben 33 Mitglieder.    \n",
       "75637    einzelnen Zünften wurden gesammelt und eine ...   \n",
       "75638                                                      \n",
       "\n",
       "                                                     Hit  \\\n",
       "75634  Beim Strählen wird das Gesicht mit einer Maske...   \n",
       "75635  In ihrer Nachfolge gibt es seit 1993 die Gelbj...   \n",
       "75636  Neue Cliquen: 1970 wurden die Erzgräber (33 Mi...   \n",
       "75637  Ein Häs mit den Konterfeis aller Masken und Ut...   \n",
       "75638  Die Zunftstube im Haus Mariagrün im Westen der...   \n",
       "\n",
       "                                            ContextAfter  \\\n",
       "75634   Die ersten Narreblättli-Ausgaben, die heute n...   \n",
       "75635                           Sie haben 33 Mitglieder.   \n",
       "75636   Die 1971 gegründete Gruppierung der Hexen wur...   \n",
       "75637   Es blieb nicht beim Häs für den Rathauschef, ...   \n",
       "75638                                                      \n",
       "\n",
       "                                                    Text  \n",
       "75634   , sondern beim Strählen in den Neudinger Gast...  \n",
       "75635    Gründungsmitglieder, die sogenannten Gelbjac...  \n",
       "75636  Sie haben 33 Mitglieder. Neue Cliquen: 1970 wu...  \n",
       "75637    einzelnen Zünften wurden gesammelt und eine ...  \n",
       "75638    Die Zunftstube im Haus Mariagrün im Westen d...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_corona.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hilfsfunktionen zur Vorbereitung der Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text_column(df, column):\n",
    "    \"\"\"\n",
    "    transforms the Dataframe-column in a lemmatized string\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        lemmas = ' '.join([x.lemma_ for x in doc])\n",
    "        text = text + lemmas\n",
    "    return text\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_äÄöÖüÜß]',' ', raw).split()\n",
    "    filtered_text = [word for word in text if word not in stopwords]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of tokenized sentences\n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    phrases = Phrases(tokenized_sentences)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = list(bigram[tokenized_sentences])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des ersten Texts (vor Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uVMUJzlpibZo",
    "outputId": "d9d2a45d-3e51-41e2-83a8-decaed115ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['februar', 'veranstalten', 'turnverein', 'bildstock', 'heringswanderung']\n"
     ]
    }
   ],
   "source": [
    "text = lemmatize_text_column(df_before_corona, 'Text')\n",
    "sentences = prepare_text(text)\n",
    "\n",
    "# sentences ist eine Liste von tokenisierten Sätzen, zum Beispiel:\n",
    "print(sentences[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des zweiten Texts (nach Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dpa', 'inkubationszeit', 'frist', 'möglich', 'ansteckung', 'krankheitsausbruch']\n"
     ]
    }
   ],
   "source": [
    "text2 = lemmatize_text_column(df_after_corona, 'Text')\n",
    "sentences2 = prepare_text(text2)\n",
    "\n",
    "print(sentences2[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training von Word2Vec auf den Text vor Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HI1V5EARibZo"
   },
   "outputs": [],
   "source": [
    "# Paramter setzen\n",
    "workers = 4                      # Use these many worker threads to train the model (=faster training with multicore machines)\n",
    "seed = 42                        # Seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gWLaiZ5cibZq"
   },
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kpbrlbf0ibZq",
    "outputId": "1f537e5c-add4-40c4-8b31-49c6f8869309"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "w2v_bc = Word2Vec(sentences=sentences,                   \n",
    "                 vector_size=300,          # Dimensionality of the word vectors\n",
    "                 window=10,                # The maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=3,              # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,         # Learning rate will linearly drop to min_alpha as training progresses\n",
    "                 sg=1,                     # Training algorithm: skip-gram if sg=1, otherwise CBOW\n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH8M_UkAibZr"
   },
   "source": [
    "## Training von Word2Vec auf den Text nach Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Gfy3LgWyibZt",
    "outputId": "0962a7be-cecd-4c1f-a1e0-ba52aff1fdc1"
   },
   "outputs": [],
   "source": [
    "w2v_ac = Word2Vec(sentences=sentences2,                   \n",
    "                 vector_size=300,                \n",
    "                 window=10,              \n",
    "                 min_count=3,             \n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,                                                    \n",
    "                 sg=1,                     \n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle speichern\n",
    "w2v_bc.save(os.path.join('../trained_models', 'w2v_bc_maske.model'))\n",
    "w2v_ac.save(os.path.join('../trained_models', 'w2v_ac_maske.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration und Vergleich der Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle laden\n",
    "w2v_bc = Word2Vec.load(os.path.join('../trained_models', 'w2v_bc_maske.model'))\n",
    "w2v_ac = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_maske.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "okTISay5ibZv",
    "outputId": "8f2fe288-c8ba-4abc-881f-a2ed7c6e69f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vollmasken', 0.5156558752059937),\n",
       " ('arbeitskleidung', 0.5113664269447327),\n",
       " ('autofahren', 0.5106855630874634),\n",
       " ('anheften', 0.5044383406639099),\n",
       " ('fast_grenzenlos', 0.5006393790245056),\n",
       " ('glitterrock', 0.49931174516677856),\n",
       " ('narr_steuer', 0.499008446931839),\n",
       " ('vorgerückt_stunde', 0.49759626388549805),\n",
       " ('mitternacht_maskenprämierung', 0.49652960896492004),\n",
       " ('spaßpäckchen', 0.4952717125415802),\n",
       " ('krummen', 0.4952276051044464),\n",
       " ('maskieren_ballbesucher', 0.4946368634700775),\n",
       " ('tierverkleidungen', 0.4939550459384918),\n",
       " ('faschingsrevolvern', 0.493613064289093),\n",
       " ('barfuß', 0.49353229999542236),\n",
       " ('handwerkszeug', 0.4918953776359558),\n",
       " ('kim_sandra', 0.4918002188205719),\n",
       " ('ergeht', 0.4912738800048828),\n",
       " ('prämierungskommission', 0.4909202754497528),\n",
       " ('motorradkutten', 0.490786075592041),\n",
       " ('quälerei_geben', 0.4901343882083893),\n",
       " ('hei_chang', 0.4901064932346344),\n",
       " ('anstrengen_bekennen', 0.4900094270706177),\n",
       " ('detailstrotzende', 0.4886721074581146),\n",
       " ('kleinkindergottesdienst', 0.48862922191619873)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'maske' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['maske'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "twofLe79ibZw",
    "outputId": "baea5bc0-fcdb-4e83-c22c-37853c505e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hygienevorschriften_einhalten', 0.6479010581970215),\n",
       " ('abseits_sitzplatzes', 0.6431371569633484),\n",
       " ('dienstleistung', 0.6429378986358643),\n",
       " ('schulgebäudes', 0.6420866250991821),\n",
       " ('mitgeführt', 0.6408758759498596),\n",
       " ('all_teilnehmende', 0.6388278007507324),\n",
       " ('meter_garantieren', 0.6383103132247925),\n",
       " ('solange_sitzplatz', 0.6380438804626465),\n",
       " ('allgemein_coronaregeln', 0.637239396572113),\n",
       " ('erreichen_sitzplatzes', 0.6360487341880798),\n",
       " ('tagesaktueller', 0.6354535818099976),\n",
       " ('beim_schwimmen', 0.6343627572059631),\n",
       " ('liegewiese', 0.6339292526245117),\n",
       " ('gemeindegesang_erlauben', 0.6332786083221436),\n",
       " ('sonstig_grund', 0.6332252025604248),\n",
       " ('namensliste', 0.6326099038124084),\n",
       " ('besucher_innen', 0.6326025724411011),\n",
       " ('präparat', 0.6323673725128174),\n",
       " ('betriebsgelände', 0.6323316693305969),\n",
       " ('schnell_selbsttest', 0.6317701935768127),\n",
       " ('maskeder', 0.6312674283981323),\n",
       " ('verkehrsmittel', 0.6311208605766296),\n",
       " ('anlieferer', 0.6309932470321655),\n",
       " ('eigen_matte', 0.6308433413505554),\n",
       " ('außer_sitzplatz', 0.6308026313781738)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'maske' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['maske'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('infektion', 0.7354362607002258),\n",
       " ('coronaviren', 0.7214908599853516),\n",
       " ('tödlich', 0.7195044159889221),\n",
       " ('coronavirus', 0.7194503545761108),\n",
       " ('corona_virus', 0.7181829214096069),\n",
       " ('aerosole', 0.708656370639801),\n",
       " ('verbreiten', 0.7079938650131226),\n",
       " ('verbreitung', 0.7076319456100464),\n",
       " ('tröpfcheninfektion', 0.7070354223251343),\n",
       " ('tröpfchen', 0.7018046379089355)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_ac.wv.most_similar(positive=['virus'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausrichtung der beiden Embedding-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Updatet script: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "    Procrustes align two gensim models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
    "    # base_embed.init_sims(replace=True)\n",
    "    # other_embed.init_sims(replace=True)\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "    \n",
    "    # re-filling the normed vectors\n",
    "    in_base_embed.wv.fill_norms(force=True)\n",
    "    in_other_embed.wv.fill_norms(force=True)\n",
    "\n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n",
    "\n",
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17067 17067\n",
      "17067 17067\n"
     ]
    }
   ],
   "source": [
    "# Ausrichtung des \"After-Corona-Modells\" an das \"Before-Corona-Modell\"\n",
    "\n",
    "w2v_ac_al = smart_procrustes_align_gensim(w2v_bc, w2v_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern\n",
    "w2v_ac_al.save(os.path.join('../trained_models', 'w2v_ac_al_maske.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laden\n",
    "w2v_ac_al = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_al_maske.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mitgeführt', 0.6408758163452148),\n",
       " ('präparat', 0.6323674917221069),\n",
       " ('maskeder', 0.6312674880027771),\n",
       " ('schwimmbecken', 0.6305027604103088),\n",
       " ('liegen_bereiten', 0.6299520134925842),\n",
       " ('zuschauer_zulassen', 0.6297780871391296),\n",
       " ('gotteshauses', 0.6286482810974121),\n",
       " ('schwimmhalle', 0.6266847252845764),\n",
       " ('dazugehören', 0.6254522204399109),\n",
       " ('desinfizierung', 0.624439001083374),\n",
       " ('kinobesucher', 0.6243300437927246),\n",
       " ('umkleideraum', 0.6223716139793396),\n",
       " ('lang_strecke', 0.6200210452079773),\n",
       " ('sanitäranlagen', 0.6197080016136169),\n",
       " ('musikinstrument', 0.6191754937171936),\n",
       " ('abs', 0.6185153722763062),\n",
       " ('verwaltungsgebäude', 0.6183631420135498),\n",
       " ('örtlichkeit', 0.6178203225135803),\n",
       " ('grundstück', 0.6168320775032043),\n",
       " ('kursteilnehmer', 0.6168129444122314),\n",
       " ('wahren_bleiben', 0.6167773604393005),\n",
       " ('umkleidekabine', 0.6165366172790527),\n",
       " ('selfies', 0.6160262227058411),\n",
       " ('gesondert', 0.6150798201560974),\n",
       " ('konzertes', 0.6146277785301208)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'maske' nach Covid-19\n",
    "w2v_ac_al.wv.most_similar(positive=['maske'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371921181678772"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_maske_bc = w2v_bc.wv['maske']  \n",
    "vector_maske_ac_al = w2v_ac_al.wv['maske'] \n",
    "\n",
    "cosine_maske = 1 - spatial.distance.cosine(vector_maske_bc, vector_maske_ac_al)\n",
    "cosine_maske"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7170157432556152"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_deutschland_bc = w2v_bc.wv['deutschland']  \n",
    "vector_deutschland_ac_al = w2v_ac_al.wv['deutschland'] \n",
    "\n",
    "cosine_deutschland = 1 - spatial.distance.cosine(vector_deutschland_bc, vector_deutschland_ac_al)\n",
    "cosine_deutschland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696213722229004"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_nachricht_bc = w2v_bc.wv['nachricht']  \n",
    "vector_nachricht_ac_al = w2v_ac_al.wv['nachricht'] \n",
    "\n",
    "cosine_nachricht = 1 - spatial.distance.cosine(vector_nachricht_bc, vector_nachricht_ac_al)\n",
    "cosine_nachricht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6534724235534668"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_schreiben_bc = w2v_bc.wv['schreiben']  \n",
    "vector_schreiben_ac_al = w2v_ac_al.wv['schreiben'] \n",
    "\n",
    "cosine_schreiben = 1 - spatial.distance.cosine(vector_schreiben_bc, vector_schreiben_ac_al)\n",
    "cosine_schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8021664023399353"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_sagen_bc = w2v_bc.wv['sagen']  \n",
    "vector_sagen_ac_al = w2v_ac_al.wv['sagen'] \n",
    "\n",
    "cosine_sagen = 1 - spatial.distance.cosine(vector_sagen_bc, vector_sagen_ac_al)\n",
    "cosine_sagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615640163421631"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mann_bc = w2v_bc.wv['mann']  \n",
    "vector_mann_ac_al = w2v_ac_al.wv['mann'] \n",
    "\n",
    "cosine_mann = 1 - spatial.distance.cosine(vector_mann_bc, vector_mann_ac_al)\n",
    "cosine_mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743870198726654"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_frau_bc = w2v_bc.wv['frau']  \n",
    "vector_frau_ac_al = w2v_ac_al.wv['frau'] \n",
    "\n",
    "cosine_frau = 1 - spatial.distance.cosine(vector_frau_bc, vector_frau_ac_al)\n",
    "cosine_frau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7617343664169312"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mensch_bc = w2v_bc.wv['mensch']  \n",
    "vector_mensch_ac_al = w2v_ac_al.wv['mensch'] \n",
    "\n",
    "cosine_mensch = 1 - spatial.distance.cosine(vector_mensch_bc, vector_mensch_ac_al)\n",
    "cosine_mensch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7040581107139587"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_montag_bc = w2v_bc.wv['montag']  \n",
    "vector_montag_ac_al = w2v_ac_al.wv['montag'] \n",
    "\n",
    "cosine_montag = 1 - spatial.distance.cosine(vector_montag_bc, vector_montag_ac_al)\n",
    "cosine_montag"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext Corona.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
