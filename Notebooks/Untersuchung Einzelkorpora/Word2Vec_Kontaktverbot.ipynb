{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq24UvixibZR"
   },
   "source": [
    "# 'Kontaktverbot' vor und nach Covid-19 - eine Untersuchung mit Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bedeutungen des Lemmas 'Kontaktverbot'\n",
    "\n",
    "Verbot des Kontaktes zu bestimmten Personen, Personengruppen oder zur Außenwelt <br>\n",
    "a) als Maßnahme des Opferschutzes <br>\n",
    "b) als Seuchenschutzmaßnahme <br>\n",
    "c) zur Isolierung von Inhaftierten, Suchtkranken o. Ä. <br> \n",
    "(Quelle: https://www.dwds.de/wb/Kontaktverbot) <br> \n",
    "<br> \n",
    "\n",
    "#### Hypothese\n",
    "\n",
    "Vor der Covid-19-Pandemie war die Lesart a) am verbreitetsten. Durch die Pandemie und die damit einhergehende Notwendigkeit von Seuchenschutzmaßnahmen gewinnt die Lesart b) an Popularität und verdrängt die anderen beiden Bedeutungen. Die Bedeutung des Lemmas wandelt sich. <br>\n",
    "<br>\n",
    "Anmerkung: Tatsache ist, dass die Pandemie aktuell für eine sehr ausgeprägte Verwendung der Lesart b) führt, die auch im mentalen Lexikon der Sprecher fest verankert ist, während diese Postion vorher Lesart a) innehatte. Ob tatsächlich ein Bedeutungswandel in all seinen Phasen stattfindet, bleibt abzuwarten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FQnxIrfibZf"
   },
   "source": [
    "## Importe und Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIZS463EibZh",
    "outputId": "d8d8fe3f-70be-4322-a081-ba1b02ef7f2f"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjlyp7Bjiu60",
    "outputId": "83b51d0b-4222-48c0-ecb3-a6a2d926c0ae"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "stopwords = stopwords.words('german')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus laden, vorbereiten und teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "QaI8RPMJibZj",
    "outputId": "7a4e7af2-20e5-4048-a2b1-341f8c0a8568"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1996-08-31</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 31.08.1996</td>\n",
       "      <td>Der Vater ist inzwischen aus seinem eigenen Ha...</td>\n",
       "      <td>Die Mutter hat durchgesetzt, daß der Vater Kon...</td>\n",
       "      <td>Sie weiß, daß er oft im Ort unterwegs ist. ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1996-09-11</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 11.09.1996</td>\n",
       "      <td>Der Täter bleibt in der Wohnung, in seinem nor...</td>\n",
       "      <td>In den USA müsse der Täter ausziehen und erhal...</td>\n",
       "      <td>Nach der engagierten Diskussion trat Bettina K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rztg_regional</td>\n",
       "      <td>1997-02-25</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Rhein-Zeitung, 25.02.1997</td>\n",
       "      <td>[...]n, nachdem sie eines der Opfer gedrängt h...</td>\n",
       "      <td>Der dritte Beschuldigte habe ein absolutes Kon...</td>\n",
       "      <td>Zu den Beschuldigten gehört nach US-Quellen au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_regional</td>\n",
       "      <td>1997-03-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Frankfurter Rundschau, 03.03.1997</td>\n",
       "      <td>[...]gen zurückzunehmen. R., dem unter anderem...</td>\n",
       "      <td>Ihm sei aber strenges Kontaktverbot auferlegt ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fr_regional</td>\n",
       "      <td>1997-12-13</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Frankfurter Rundschau, 13.12.1997</td>\n",
       "      <td>[...]ungsauflagen der Justiz, ohne daß das für...</td>\n",
       "      <td>Weil der Polizei aber Auflagen nicht mitgeteil...</td>\n",
       "      <td>Herrmann: \"Selbst erneut begangene Straftaten ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Corpus        Date    Genre                               Bibl  \\\n",
       "No.                                                                          \n",
       "1    saar_regional  1996-08-31  Zeitung    Saarbrücker Zeitung, 31.08.1996   \n",
       "2    saar_regional  1996-09-11  Zeitung    Saarbrücker Zeitung, 11.09.1996   \n",
       "3    rztg_regional  1997-02-25  Zeitung          Rhein-Zeitung, 25.02.1997   \n",
       "4      fr_regional  1997-03-03  Zeitung  Frankfurter Rundschau, 03.03.1997   \n",
       "5      fr_regional  1997-12-13  Zeitung  Frankfurter Rundschau, 13.12.1997   \n",
       "\n",
       "                                         ContextBefore  \\\n",
       "No.                                                      \n",
       "1    Der Vater ist inzwischen aus seinem eigenen Ha...   \n",
       "2    Der Täter bleibt in der Wohnung, in seinem nor...   \n",
       "3    [...]n, nachdem sie eines der Opfer gedrängt h...   \n",
       "4    [...]gen zurückzunehmen. R., dem unter anderem...   \n",
       "5    [...]ungsauflagen der Justiz, ohne daß das für...   \n",
       "\n",
       "                                                   Hit  \\\n",
       "No.                                                      \n",
       "1    Die Mutter hat durchgesetzt, daß der Vater Kon...   \n",
       "2    In den USA müsse der Täter ausziehen und erhal...   \n",
       "3    Der dritte Beschuldigte habe ein absolutes Kon...   \n",
       "4    Ihm sei aber strenges Kontaktverbot auferlegt ...   \n",
       "5    Weil der Polizei aber Auflagen nicht mitgeteil...   \n",
       "\n",
       "                                          ContextAfter  \n",
       "No.                                                     \n",
       "1    Sie weiß, daß er oft im Ort unterwegs ist. ent...  \n",
       "2    Nach der engagierten Diskussion trat Bettina K...  \n",
       "3    Zu den Beschuldigten gehört nach US-Quellen au...  \n",
       "4                                                  NaN  \n",
       "5    Herrmann: \"Selbst erneut begangene Straftaten ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# die Datei enthält alle Treffer des Lemmas 'kontaktverbot' im ZDL-Regionalkorpus des DWDS \n",
    "# mit jeweils einem Satz Kontext davor und danach\n",
    "\n",
    "df = pd.read_csv('../data/kontaktverbot_1993-2021.csv', sep=',', index_col='No.', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN durch Whitespace ersetzen\n",
    "\n",
    "df = df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wörter, die mit [...] anfangen löschen\n",
    "\n",
    "expression = '\\[...]\\w*'\n",
    "df = df.replace(to_replace = expression, value = ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bevor die Spalten verbunden werden: Whitespace einfügen, um ein Aneinanderkleben der Wörter zu verhindern\n",
    "\n",
    "df['ContextBefore'] = df['ContextBefore'].astype(str) + ' '\n",
    "df['ContextAfter'] = ' ' + df['ContextAfter'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1996-08-31</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 31.08.1996</td>\n",
       "      <td>Der Vater ist inzwischen aus seinem eigenen Ha...</td>\n",
       "      <td>Die Mutter hat durchgesetzt, daß der Vater Kon...</td>\n",
       "      <td>Sie weiß, daß er oft im Ort unterwegs ist. en...</td>\n",
       "      <td>Der Vater ist inzwischen aus seinem eigenen Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1996-09-11</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 11.09.1996</td>\n",
       "      <td>Der Täter bleibt in der Wohnung, in seinem nor...</td>\n",
       "      <td>In den USA müsse der Täter ausziehen und erhal...</td>\n",
       "      <td>Nach der engagierten Diskussion trat Bettina ...</td>\n",
       "      <td>Der Täter bleibt in der Wohnung, in seinem nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rztg_regional</td>\n",
       "      <td>1997-02-25</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Rhein-Zeitung, 25.02.1997</td>\n",
       "      <td>, nachdem sie eines der Opfer gedrängt hätten...</td>\n",
       "      <td>Der dritte Beschuldigte habe ein absolutes Kon...</td>\n",
       "      <td>Zu den Beschuldigten gehört nach US-Quellen a...</td>\n",
       "      <td>, nachdem sie eines der Opfer gedrängt hätten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr_regional</td>\n",
       "      <td>1997-03-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Frankfurter Rundschau, 03.03.1997</td>\n",
       "      <td>zurückzunehmen. R., dem unter anderem sexuel...</td>\n",
       "      <td>Ihm sei aber strenges Kontaktverbot auferlegt ...</td>\n",
       "      <td></td>\n",
       "      <td>zurückzunehmen. R., dem unter anderem sexuel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fr_regional</td>\n",
       "      <td>1997-12-13</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Frankfurter Rundschau, 13.12.1997</td>\n",
       "      <td>der Justiz, ohne daß das für sie Konsequenze...</td>\n",
       "      <td>Weil der Polizei aber Auflagen nicht mitgeteil...</td>\n",
       "      <td>Herrmann: \"Selbst erneut begangene Straftaten...</td>\n",
       "      <td>der Justiz, ohne daß das für sie Konsequenze...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Corpus        Date    Genre                               Bibl  \\\n",
       "No.                                                                          \n",
       "1    saar_regional  1996-08-31  Zeitung    Saarbrücker Zeitung, 31.08.1996   \n",
       "2    saar_regional  1996-09-11  Zeitung    Saarbrücker Zeitung, 11.09.1996   \n",
       "3    rztg_regional  1997-02-25  Zeitung          Rhein-Zeitung, 25.02.1997   \n",
       "4      fr_regional  1997-03-03  Zeitung  Frankfurter Rundschau, 03.03.1997   \n",
       "5      fr_regional  1997-12-13  Zeitung  Frankfurter Rundschau, 13.12.1997   \n",
       "\n",
       "                                         ContextBefore  \\\n",
       "No.                                                      \n",
       "1    Der Vater ist inzwischen aus seinem eigenen Ha...   \n",
       "2    Der Täter bleibt in der Wohnung, in seinem nor...   \n",
       "3     , nachdem sie eines der Opfer gedrängt hätten...   \n",
       "4      zurückzunehmen. R., dem unter anderem sexuel...   \n",
       "5      der Justiz, ohne daß das für sie Konsequenze...   \n",
       "\n",
       "                                                   Hit  \\\n",
       "No.                                                      \n",
       "1    Die Mutter hat durchgesetzt, daß der Vater Kon...   \n",
       "2    In den USA müsse der Täter ausziehen und erhal...   \n",
       "3    Der dritte Beschuldigte habe ein absolutes Kon...   \n",
       "4    Ihm sei aber strenges Kontaktverbot auferlegt ...   \n",
       "5    Weil der Polizei aber Auflagen nicht mitgeteil...   \n",
       "\n",
       "                                          ContextAfter  \\\n",
       "No.                                                      \n",
       "1     Sie weiß, daß er oft im Ort unterwegs ist. en...   \n",
       "2     Nach der engagierten Diskussion trat Bettina ...   \n",
       "3     Zu den Beschuldigten gehört nach US-Quellen a...   \n",
       "4                                                        \n",
       "5     Herrmann: \"Selbst erneut begangene Straftaten...   \n",
       "\n",
       "                                                  Text  \n",
       "No.                                                     \n",
       "1    Der Vater ist inzwischen aus seinem eigenen Ha...  \n",
       "2    Der Täter bleibt in der Wohnung, in seinem nor...  \n",
       "3     , nachdem sie eines der Opfer gedrängt hätten...  \n",
       "4      zurückzunehmen. R., dem unter anderem sexuel...  \n",
       "5      der Justiz, ohne daß das für sie Konsequenze...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text zu einer Spalte verbinden\n",
    "\n",
    "columns = ['ContextBefore', 'Hit', 'ContextAfter']\n",
    "\n",
    "df['Text'] = df[columns].astype(str).sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6uioii_SibZl"
   },
   "outputs": [],
   "source": [
    "# Korpus in 2 Teilkorpora splitten: vor und nach Covid-19 (dem Ausbruch in Deutschland)\n",
    "# hier wurde die Grenze zwischen Januar und Februar 2020 gezogen (es wird sich noch zeigen, inwiefern sich das bewährt)\n",
    "\n",
    "df_before_corona = df.iloc[:1421,:]\n",
    "df_after_corona = df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>maz_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Allgemeine Zeitung, 01.02.2020</td>\n",
       "      <td>Karte gegen einen Trainer.</td>\n",
       "      <td>Sandro Schwarz, ehemaliger Coach des FSV Mainz...</td>\n",
       "      <td></td>\n",
       "      <td>Karte gegen einen Trainer. Sandro Schwarz, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>frt_regional</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Fränkischer Tag, 03.02.2020</td>\n",
       "      <td>Er konnte jedoch kurz darauf kontaktiert werden.</td>\n",
       "      <td>Neben einer Strafanzeige wegen Bedrohung und S...</td>\n",
       "      <td></td>\n",
       "      <td>Er konnte jedoch kurz darauf kontaktiert werde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>kn_regional</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Kieler Nachrichten, 14.02.2020</td>\n",
       "      <td>indem Angreifer des Wohnortes verwiesen werd...</td>\n",
       "      <td>Bieler zufolge war der 24-Jährige mit einem Ko...</td>\n",
       "      <td>Dagegen habe er verstoßen.</td>\n",
       "      <td>indem Angreifer des Wohnortes verwiesen werd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>kn_regional</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Kieler Nachrichten, 15.02.2020</td>\n",
       "      <td>Vater des neben dem Opfer gefundenen Säuglin...</td>\n",
       "      <td>Zwar hatte das Amtsgericht Rendsburg gegen ihn...</td>\n",
       "      <td>Doch beide checkten zusammen in das Hotel in ...</td>\n",
       "      <td>Vater des neben dem Opfer gefundenen Säuglin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>ta_regional</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Thüringer Allgemeine, 20.02.2020</td>\n",
       "      <td>Zu Details folgten keine Angaben.</td>\n",
       "      <td>Denkbar sind aber Verlegungen, Kontaktverbote ...</td>\n",
       "      <td>Die Massenschlägerei gebe aus Sicht der Behör...</td>\n",
       "      <td>Zu Details folgten keine Angaben. Denkbar sind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Corpus        Date    Genre                              Bibl  \\\n",
       "No.                                                                         \n",
       "1423  maz_regional  2020-02-01  Zeitung    Allgemeine Zeitung, 01.02.2020   \n",
       "1424  frt_regional  2020-02-03  Zeitung       Fränkischer Tag, 03.02.2020   \n",
       "1425   kn_regional  2020-02-14  Zeitung    Kieler Nachrichten, 14.02.2020   \n",
       "1426   kn_regional  2020-02-15  Zeitung    Kieler Nachrichten, 15.02.2020   \n",
       "1427   ta_regional  2020-02-20  Zeitung  Thüringer Allgemeine, 20.02.2020   \n",
       "\n",
       "                                          ContextBefore  \\\n",
       "No.                                                       \n",
       "1423                        Karte gegen einen Trainer.    \n",
       "1424  Er konnte jedoch kurz darauf kontaktiert werden.    \n",
       "1425    indem Angreifer des Wohnortes verwiesen werd...   \n",
       "1426    Vater des neben dem Opfer gefundenen Säuglin...   \n",
       "1427                 Zu Details folgten keine Angaben.    \n",
       "\n",
       "                                                    Hit  \\\n",
       "No.                                                       \n",
       "1423  Sandro Schwarz, ehemaliger Coach des FSV Mainz...   \n",
       "1424  Neben einer Strafanzeige wegen Bedrohung und S...   \n",
       "1425  Bieler zufolge war der 24-Jährige mit einem Ko...   \n",
       "1426  Zwar hatte das Amtsgericht Rendsburg gegen ihn...   \n",
       "1427  Denkbar sind aber Verlegungen, Kontaktverbote ...   \n",
       "\n",
       "                                           ContextAfter  \\\n",
       "No.                                                       \n",
       "1423                                                      \n",
       "1424                                                      \n",
       "1425                         Dagegen habe er verstoßen.   \n",
       "1426   Doch beide checkten zusammen in das Hotel in ...   \n",
       "1427   Die Massenschlägerei gebe aus Sicht der Behör...   \n",
       "\n",
       "                                                   Text  \n",
       "No.                                                      \n",
       "1423    Karte gegen einen Trainer. Sandro Schwarz, e...  \n",
       "1424  Er konnte jedoch kurz darauf kontaktiert werde...  \n",
       "1425    indem Angreifer des Wohnortes verwiesen werd...  \n",
       "1426    Vater des neben dem Opfer gefundenen Säuglin...  \n",
       "1427  Zu Details folgten keine Angaben. Denkbar sind...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_corona.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hilfsfunktionen zur Vorbereitung der Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text_column(df, column):\n",
    "    \"\"\"\n",
    "    transforms the Dataframe-column in a lemmatized string\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        lemmas = ' '.join([x.lemma_ for x in doc])\n",
    "        text = text + lemmas\n",
    "    return text\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_äÄöÖüÜß]',' ', raw).split()\n",
    "    filtered_text = [word for word in text if word not in stopwords]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of tokenized sentences\n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    phrases = Phrases(tokenized_sentences)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = list(bigram[tokenized_sentences])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des ersten Texts (vor Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uVMUJzlpibZo",
    "outputId": "d9d2a45d-3e51-41e2-83a8-decaed115ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urteil', 'streng_auflage', 'kontaktverbot', 'therapiekontrolle', 'schwester', 'bleiben', 'aussage', 'gericht', 'ersparen']\n"
     ]
    }
   ],
   "source": [
    "text = lemmatize_text_column(df_before_corona, 'Text')\n",
    "sentences = prepare_text(text)\n",
    "\n",
    "# sentences ist eine Liste von tokenisierten Sätzen, zum Beispiel:\n",
    "print(sentences[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des zweiten Texts (nach Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mai', 'sowie']\n"
     ]
    }
   ],
   "source": [
    "text2 = lemmatize_text_column(df_after_corona, 'Text')\n",
    "sentences2 = prepare_text(text2)\n",
    "\n",
    "print(sentences2[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sonntag', 'bundesweit', 'kontaktverbot', 'verschärfen', 'birgit', 'schellbach', 'einschränkung', 'bundes', 'landesregierung', 'sonntag', 'verständigen', 'kontaktverbote', 'gelten', 'konsequenz', 'logisch']\n"
     ]
    }
   ],
   "source": [
    "print(sentences2[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training von Word2Vec auf den Text vor Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HI1V5EARibZo"
   },
   "outputs": [],
   "source": [
    "# Paramter setzen\n",
    "workers = 4                      # Use these many worker threads to train the model (=faster training with multicore machines)\n",
    "seed = 42                        # Seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gWLaiZ5cibZq"
   },
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kpbrlbf0ibZq",
    "outputId": "1f537e5c-add4-40c4-8b31-49c6f8869309"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "w2v_bc = Word2Vec(sentences=sentences,                   \n",
    "                 vector_size=300,                 # Dimensionality of the word vectors\n",
    "                 window=10,                # The maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=3,              # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,         # Learning rate will linearly drop to min_alpha as training progresses\n",
    "                 sg=1,                     # Training algorithm: skip-gram if sg=1, otherwise CBOW\n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH8M_UkAibZr"
   },
   "source": [
    "## Training von Word2Vec auf den Text nach Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Gfy3LgWyibZt",
    "outputId": "0962a7be-cecd-4c1f-a1e0-ba52aff1fdc1"
   },
   "outputs": [],
   "source": [
    "w2v_ac = Word2Vec(sentences=sentences2,                   \n",
    "                 vector_size=300,                \n",
    "                 window=10,              \n",
    "                 min_count=3,             \n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,                                                    \n",
    "                 sg=1,                     \n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle speichern\n",
    "w2v_bc.save(os.path.join('../trained_models', 'w2v_bc_kontaktverbot.model'))\n",
    "w2v_ac.save(os.path.join('../trained_models', 'w2v_ac_kontaktverbot.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration und Vergleich der Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle laden\n",
    "w2v_bc = Word2Vec.load(os.path.join('../trained_models', 'w2v_bc_kontaktverbot.model'))\n",
    "w2v_ac = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_kontaktverbot.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "okTISay5ibZv",
    "outputId": "8f2fe288-c8ba-4abc-881f-a2ed7c6e69f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polizeilich', 0.9988954067230225),\n",
       " ('sprechen', 0.9988211989402771),\n",
       " ('sogar', 0.9988188743591309),\n",
       " ('abend', 0.9988176822662354),\n",
       " ('verlassen', 0.9988148808479309),\n",
       " ('anzeige', 0.9988086819648743),\n",
       " ('zurück', 0.9988077878952026),\n",
       " ('außerdem', 0.998799741268158),\n",
       " ('häuslich_gewalt', 0.9987961053848267),\n",
       " ('verfolgen', 0.9987960457801819),\n",
       " ('allerdings', 0.9987948536872864),\n",
       " ('nie', 0.9987946152687073),\n",
       " ('daraufhin', 0.9987844824790955),\n",
       " ('trotz', 0.9987785220146179),\n",
       " ('straße', 0.9987766146659851),\n",
       " ('übergriff', 0.9987765550613403),\n",
       " ('suchen', 0.9987765550613403),\n",
       " ('zeit', 0.9987756609916687),\n",
       " ('bislang', 0.9987740516662598),\n",
       " ('lebensgefährtin', 0.9987710118293762),\n",
       " ('melden', 0.9987708330154419),\n",
       " ('polizei', 0.9987677335739136),\n",
       " ('näherungs', 0.9987666010856628),\n",
       " ('ignorieren', 0.9987660646438599),\n",
       " ('opfer', 0.9987608790397644)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'kontaktverbot' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['kontaktverbot'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "twofLe79ibZw",
    "outputId": "baea5bc0-fcdb-4e83-c22c-37853c505e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kontaktverbote', 0.9955378770828247),\n",
       " ('all', 0.9946960806846619),\n",
       " ('maßnahme', 0.9946514964103699),\n",
       " ('mensch', 0.9943512082099915),\n",
       " ('einschränkung', 0.9940256476402283),\n",
       " ('strikt', 0.9939620494842529),\n",
       " ('müssen', 0.993706226348877),\n",
       " ('streng', 0.9935687780380249),\n",
       " ('ganz', 0.9935296773910522),\n",
       " ('märz', 0.9934855103492737),\n",
       " ('bürger', 0.9934358596801758),\n",
       " ('gut', 0.9934248328208923),\n",
       " ('mehr', 0.9934183359146118),\n",
       " ('regel', 0.9933581352233887),\n",
       " ('meist', 0.9933546185493469),\n",
       " ('weit', 0.9933455586433411),\n",
       " ('abstand', 0.9933310747146606),\n",
       " ('geltend', 0.9932850003242493),\n",
       " ('erlassen', 0.993249237537384),\n",
       " ('gruppe', 0.9932101368904114),\n",
       " ('zudem', 0.9930806756019592),\n",
       " ('april', 0.9930447936058044),\n",
       " ('ab', 0.9930330514907837),\n",
       " ('groß', 0.9930089712142944),\n",
       " ('seit', 0.9929520487785339)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'kontaktverbot' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['kontaktverbot'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('internet', 0.9993537068367004),\n",
       " ('kommend_woche', 0.9993150234222412),\n",
       " ('recht', 0.9993101358413696),\n",
       " ('reise', 0.9992884993553162),\n",
       " ('kita', 0.9992877244949341),\n",
       " ('eindämmen', 0.9992866516113281),\n",
       " ('wohnen', 0.9992834329605103),\n",
       " ('triefen', 0.9992813467979431),\n",
       " ('jemand', 0.9992809891700745),\n",
       " ('schulschließungen', 0.9992790222167969)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_ac.wv.most_similar(positive=['virus'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausrichtung der beiden Embedding-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Updatet script: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "    Procrustes align two gensim models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
    "    # base_embed.init_sims(replace=True)\n",
    "    # other_embed.init_sims(replace=True)\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "    \n",
    "    # re-filling the normed vectors\n",
    "    in_base_embed.wv.fill_norms(force=True)\n",
    "    in_other_embed.wv.fill_norms(force=True)\n",
    "\n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n",
    "\n",
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012 1012\n",
      "1012 1012\n"
     ]
    }
   ],
   "source": [
    "# Ausrichtung des \"After-Corona-Modells\" an das \"Before-Corona-Modell\"\n",
    "\n",
    "w2v_ac_al = smart_procrustes_align_gensim(w2v_bc, w2v_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern\n",
    "w2v_ac_al.save(os.path.join('../trained_models', 'w2v_ac_al_kontaktverbot.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laden\n",
    "w2v_ac_al = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_al_kontaktverbot.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kontaktverbote', 0.9955378174781799),\n",
       " ('all', 0.9946959614753723),\n",
       " ('maßnahme', 0.9946514368057251),\n",
       " ('mensch', 0.9943512678146362),\n",
       " ('müssen', 0.9937061071395874),\n",
       " ('streng', 0.9935687780380249),\n",
       " ('ganz', 0.9935296773910522),\n",
       " ('märz', 0.9934853911399841),\n",
       " ('gut', 0.9934248328208923),\n",
       " ('mehr', 0.9934183359146118),\n",
       " ('regel', 0.9933581948280334),\n",
       " ('meist', 0.9933546781539917),\n",
       " ('weit', 0.9933455586433411),\n",
       " ('abstand', 0.9933310747146606),\n",
       " ('erlassen', 0.9932493567466736),\n",
       " ('zudem', 0.9930806756019592),\n",
       " ('april', 0.9930447936058044),\n",
       " ('ab', 0.9930331707000732),\n",
       " ('groß', 0.9930089712142944),\n",
       " ('seit', 0.9929519891738892),\n",
       " ('fall', 0.9928945302963257),\n",
       " ('einsatz', 0.9928871989250183),\n",
       " ('wenig', 0.9928624629974365),\n",
       " ('ja', 0.9928194284439087),\n",
       " ('halten', 0.9927875995635986)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'kontaktverbot' nach Covid-19\n",
    "w2v_ac_al.wv.most_similar(positive=['kontaktverbot'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946087002754211"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_kontaktverbot_bc = w2v_bc.wv['kontaktverbot']  \n",
    "vector_kontaktverbot_ac_al = w2v_ac_al.wv['kontaktverbot'] \n",
    "\n",
    "cosine_kontaktverbot = 1 - spatial.distance.cosine(vector_kontaktverbot_bc, vector_kontaktverbot_ac_al)\n",
    "cosine_kontaktverbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994295239448547"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_deutschland_bc = w2v_bc.wv['deutschland']  \n",
    "vector_deutschland_ac_al = w2v_ac_al.wv['deutschland'] \n",
    "\n",
    "cosine_deutschland = 1 - spatial.distance.cosine(vector_deutschland_bc, vector_deutschland_ac_al)\n",
    "cosine_deutschland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992865920066833"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_nachricht_bc = w2v_bc.wv['nachricht']  \n",
    "vector_nachricht_ac_al = w2v_ac_al.wv['nachricht'] \n",
    "\n",
    "cosine_nachricht = 1 - spatial.distance.cosine(vector_nachricht_bc, vector_nachricht_ac_al)\n",
    "cosine_nachricht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992007613182068"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_schreiben_bc = w2v_bc.wv['schreiben']  \n",
    "vector_schreiben_ac_al = w2v_ac_al.wv['schreiben'] \n",
    "\n",
    "cosine_schreiben = 1 - spatial.distance.cosine(vector_schreiben_bc, vector_schreiben_ac_al)\n",
    "cosine_schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986796379089355"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_sagen_bc = w2v_bc.wv['sagen']  \n",
    "vector_sagen_ac_al = w2v_ac_al.wv['sagen'] \n",
    "\n",
    "cosine_sagen = 1 - spatial.distance.cosine(vector_sagen_bc, vector_sagen_ac_al)\n",
    "cosine_sagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987703561782837"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mann_bc = w2v_bc.wv['mann']  \n",
    "vector_mann_ac_al = w2v_ac_al.wv['mann'] \n",
    "\n",
    "cosine_mann = 1 - spatial.distance.cosine(vector_mann_bc, vector_mann_ac_al)\n",
    "cosine_mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975944757461548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_frau_bc = w2v_bc.wv['frau']  \n",
    "vector_frau_ac_al = w2v_ac_al.wv['frau'] \n",
    "\n",
    "cosine_frau = 1 - spatial.distance.cosine(vector_frau_bc, vector_frau_ac_al)\n",
    "cosine_frau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957024455070496"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mensch_bc = w2v_bc.wv['mensch']  \n",
    "vector_mensch_ac_al = w2v_ac_al.wv['mensch'] \n",
    "\n",
    "cosine_mensch = 1 - spatial.distance.cosine(vector_mensch_bc, vector_mensch_ac_al)\n",
    "cosine_mensch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994257688522339"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_montag_bc = w2v_bc.wv['montag']  \n",
    "vector_montag_ac_al = w2v_ac_al.wv['montag'] \n",
    "\n",
    "cosine_montag = 1 - spatial.distance.cosine(vector_montag_bc, vector_montag_ac_al)\n",
    "cosine_montag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### durchschnittliche Cosinus-Ähnlichkeit, Standardweichung und 'Normalbereich'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- von allen Wörtern/Vektoren, die in beiden Modellen vorkommen jeweils die Cosinus-Ähnlichkeit berechnen (also zueinander zwischen den Modellen)\n",
    "- durchschnittliche Ähnlichkeit und Standardabweichung berechnen, um einen 'Normalbereich' zu ermitteln\n",
    "- liegt der Wert der Cosinus-Ähnlichkeit (desselben Lemmas zwischen den Modellen) unter dem Normalbereich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle Wörter, die in beiden Modellen vorkommmen\n",
    "\n",
    "vocab_bc = set(w2v_bc.wv.index_to_key)\n",
    "vocab_ac_al = set(w2v_ac_al.wv.index_to_key)\n",
    "\n",
    "common_vocab = vocab_bc & vocab_ac_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosinus-Ähnlichkeit zwischen dem Wort in den beiden Modellen berechnen\n",
    "\n",
    "cosines = {}\n",
    "\n",
    "for word in common_vocab:\n",
    "    vector_bc = w2v_bc.wv[word]  \n",
    "    vector_ac_al = w2v_ac_al.wv[word] \n",
    "    cosine = 1 - spatial.distance.cosine(vector_bc, vector_ac_al)\n",
    "    cosines[word] = cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entlassen</th>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anwalt</th>\n",
       "      <td>0.999413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>streit</th>\n",
       "      <td>0.999276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ändern</th>\n",
       "      <td>0.999417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heraus</th>\n",
       "      <td>0.999418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dienst</th>\n",
       "      <td>0.999359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.999471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diskussion</th>\n",
       "      <td>0.998984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schaden</th>\n",
       "      <td>0.999253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>szene</th>\n",
       "      <td>0.999132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cosine\n",
       "entlassen   0.999407\n",
       "anwalt      0.999413\n",
       "streit      0.999276\n",
       "ändern      0.999417\n",
       "heraus      0.999418\n",
       "...              ...\n",
       "dienst      0.999359\n",
       "o           0.999471\n",
       "diskussion  0.998984\n",
       "schaden     0.999253\n",
       "szene       0.999132\n",
       "\n",
       "[1012 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df = pd.DataFrame.from_dict(cosines, orient='index', columns=['cosine'])\n",
    "cosine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992103307496889"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# durchschnittliche Cosinus-Ähnlichkeit der Wörter der beiden Modelle \n",
    "\n",
    "statistics.mean(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007369513531318355"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardabweichung\n",
    "\n",
    "statistics.stdev(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Normalbereich der Cosinus-Ähnlichkeit liegt über 0.9984733793965571\n"
     ]
    }
   ],
   "source": [
    "# 'Normalbereich' der Cosinus-Ähnlichkeit\n",
    "\n",
    "border = statistics.mean(cosine_df['cosine']) - statistics.stdev(cosine_df['cosine'])\n",
    "\n",
    "print('der Normalbereich der Cosinus-Ähnlichkeit liegt über', border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_kontaktverbot < border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Cosinus-Ähnlichkeit zwischen den beiden Vektoren für 'Kontaktverbot' liegt unterhalb des Normalbereichs. <br>\n",
    "Die Hypothese kann als verifiziert gelten. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext Corona.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
