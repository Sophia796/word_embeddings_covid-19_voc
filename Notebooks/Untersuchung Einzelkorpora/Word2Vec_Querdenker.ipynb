{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq24UvixibZR"
   },
   "source": [
    "# 'Querdenker' vor und nach Covid-19 - eine Untersuchung mit Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bedeutung des Lemmas 'Querdenker'\n",
    "\n",
    "Person, die eigenwillige und mit etablierten Positionen meist nicht vereinbare Ideen oder Ansichten vertritt, äußert und deshalb oft auf Unverständnis oder Widerstand trifft <br>\n",
    "(Quelle: https://www.dwds.de/wb/Querdenker) <br>\n",
    "<br>\n",
    "[spezieller] in der COVID-19-Pandemie: Person, die die Coronamaßnahmen für überzogen hält und sich dabei zum Teil auf wissenschaftliche Minderheitenmeinungen beruft, vor allem aber solche Informationen zur Bekräftigung ihrer Überzeugung heranzieht, die bei Experten als unsachlich bzw. falsch oder als zu stark vereinfacht gelten <br>\n",
    "(Quelle: https://www.dwds.de/themenglossar/Corona#glossar-Q) <br>\n",
    " \n",
    "\n",
    "#### Hypothese\n",
    "\n",
    "Durch die Pandemie und die daraus entstandenen Bewegung der sogenannten Querdenker wird das Lemma populärer, die Bedeutung spezifiziert sich und verdrängt die ursprüngliche Bedeutung. Die Bedeutung des Lemmas wandelt sich und wird möglicherweise negativ konnotiert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FQnxIrfibZf"
   },
   "source": [
    "## Importe und Datenvorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIZS463EibZh",
    "outputId": "d8d8fe3f-70be-4322-a081-ba1b02ef7f2f"
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import statistics \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from joblib import Parallel, delayed  \n",
    "from nltk.corpus import stopwords\n",
    "from scipy import spatial\n",
    "from sklearn.manifold import TSNE\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjlyp7Bjiu60",
    "outputId": "83b51d0b-4222-48c0-ecb3-a6a2d926c0ae"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "stopwords = stopwords.words('german')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Korpus laden und teilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "QaI8RPMJibZj",
    "outputId": "7a4e7af2-20e5-4048-a2b1-341f8c0a8568"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-04-28</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 28.04.1993</td>\n",
       "      <td>[...]andes war, bedankte sich Sauer mit einer ...</td>\n",
       "      <td>Gerade Thiery als \"Querdenker\" habe mit seinen...</td>\n",
       "      <td>Edgar Schuster, Ortsvorsteher von Noswendel un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-07-09</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 09.07.1993</td>\n",
       "      <td>[...]tellvertretend für die zwei \"Lager\" äußer...</td>\n",
       "      <td>Der Ehrenvorsitzende der Völklinger CDU, Dr. R...</td>\n",
       "      <td>Angesichts der schon in einem Jahr stattfinde[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-09-02</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 02.09.1993</td>\n",
       "      <td>[...]ant zu Heinrich Böll ist, oder ob ihn die...</td>\n",
       "      <td>\"Ich fühle mich geschmeichelt\", so der gerührt...</td>\n",
       "      <td>Dennoch, konstatierte Ratlosigkeit auch bei Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-10-15</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 15.10.1993</td>\n",
       "      <td>Ab sofort erhältlich</td>\n",
       "      <td>Schade, daß das Buch auch auf die Rolle von Fr...</td>\n",
       "      <td>Die Neuerscheinung jed[...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-11-12</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 12.11.1993</td>\n",
       "      <td>[...] profilierten Politikern, die auch einmal...</td>\n",
       "      <td>Querdenker erzielen aber nie hundertprozentige...</td>\n",
       "      <td>Und auch bei der anstehenden Besetzung der Plä...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-04-28  Zeitung  Saarbrücker Zeitung, 28.04.1993   \n",
       "1  saar_regional  1993-07-09  Zeitung  Saarbrücker Zeitung, 09.07.1993   \n",
       "2  saar_regional  1993-09-02  Zeitung  Saarbrücker Zeitung, 02.09.1993   \n",
       "3  saar_regional  1993-10-15  Zeitung  Saarbrücker Zeitung, 15.10.1993   \n",
       "4  saar_regional  1993-11-12  Zeitung  Saarbrücker Zeitung, 12.11.1993   \n",
       "\n",
       "                                       ContextBefore  \\\n",
       "0  [...]andes war, bedankte sich Sauer mit einer ...   \n",
       "1  [...]tellvertretend für die zwei \"Lager\" äußer...   \n",
       "2  [...]ant zu Heinrich Böll ist, oder ob ihn die...   \n",
       "3                               Ab sofort erhältlich   \n",
       "4  [...] profilierten Politikern, die auch einmal...   \n",
       "\n",
       "                                                 Hit  \\\n",
       "0  Gerade Thiery als \"Querdenker\" habe mit seinen...   \n",
       "1  Der Ehrenvorsitzende der Völklinger CDU, Dr. R...   \n",
       "2  \"Ich fühle mich geschmeichelt\", so der gerührt...   \n",
       "3  Schade, daß das Buch auch auf die Rolle von Fr...   \n",
       "4  Querdenker erzielen aber nie hundertprozentige...   \n",
       "\n",
       "                                        ContextAfter  \n",
       "0  Edgar Schuster, Ortsvorsteher von Noswendel un...  \n",
       "1  Angesichts der schon in einem Jahr stattfinde[...  \n",
       "2  Dennoch, konstatierte Ratlosigkeit auch bei Wo...  \n",
       "3                        Die Neuerscheinung jed[...]  \n",
       "4  Und auch bei der anstehenden Besetzung der Plä...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# die Datei enthält alle Treffer des Lemmas 'querdenker' im ZDL-Regionalkorpus des DWDS \n",
    "# mit jeweils einem Satz Kontext davor und danach\n",
    "\n",
    "df = pd.read_csv('../data/querdenker_1993-2021.csv', sep=',', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN durch Whitespace ersetzen\n",
    "\n",
    "df = df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wörter, die mit [...] anfangen löschen\n",
    "\n",
    "expression = '\\[...]\\w*'\n",
    "df = df.replace(to_replace = expression, value = ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bevor die Spalten verbunden werden: Whitespace einfügen, um ein Aneinanderkleben der Wörter zu verhindern\n",
    "\n",
    "df['ContextBefore'] = df['ContextBefore'].astype(str) + ' '\n",
    "df['ContextAfter'] = ' ' + df['ContextAfter'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-04-28</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 28.04.1993</td>\n",
       "      <td>war, bedankte sich Sauer mit einer Ehrenurku...</td>\n",
       "      <td>Gerade Thiery als \"Querdenker\" habe mit seinen...</td>\n",
       "      <td>Edgar Schuster, Ortsvorsteher von Noswendel u...</td>\n",
       "      <td>war, bedankte sich Sauer mit einer Ehrenurku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-07-09</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 09.07.1993</td>\n",
       "      <td>für die zwei \"Lager\" äußerten.</td>\n",
       "      <td>Der Ehrenvorsitzende der Völklinger CDU, Dr. R...</td>\n",
       "      <td>Angesichts der schon in einem Jahr stattfinde</td>\n",
       "      <td>für die zwei \"Lager\" äußerten. Der Ehrenvors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-09-02</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 02.09.1993</td>\n",
       "      <td>zu Heinrich Böll ist, oder ob ihn dieser inn...</td>\n",
       "      <td>\"Ich fühle mich geschmeichelt\", so der gerührt...</td>\n",
       "      <td>Dennoch, konstatierte Ratlosigkeit auch bei W...</td>\n",
       "      <td>zu Heinrich Böll ist, oder ob ihn dieser inn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-10-15</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 15.10.1993</td>\n",
       "      <td>Ab sofort erhältlich</td>\n",
       "      <td>Schade, daß das Buch auch auf die Rolle von Fr...</td>\n",
       "      <td>Die Neuerscheinung jed</td>\n",
       "      <td>Ab sofort erhältlich Schade, daß das Buch auch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saar_regional</td>\n",
       "      <td>1993-11-12</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Saarbrücker Zeitung, 12.11.1993</td>\n",
       "      <td>profilierten Politikern, die auch einmal geg...</td>\n",
       "      <td>Querdenker erzielen aber nie hundertprozentige...</td>\n",
       "      <td>Und auch bei der anstehenden Besetzung der Pl...</td>\n",
       "      <td>profilierten Politikern, die auch einmal geg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Corpus        Date    Genre                             Bibl  \\\n",
       "0  saar_regional  1993-04-28  Zeitung  Saarbrücker Zeitung, 28.04.1993   \n",
       "1  saar_regional  1993-07-09  Zeitung  Saarbrücker Zeitung, 09.07.1993   \n",
       "2  saar_regional  1993-09-02  Zeitung  Saarbrücker Zeitung, 02.09.1993   \n",
       "3  saar_regional  1993-10-15  Zeitung  Saarbrücker Zeitung, 15.10.1993   \n",
       "4  saar_regional  1993-11-12  Zeitung  Saarbrücker Zeitung, 12.11.1993   \n",
       "\n",
       "                                       ContextBefore  \\\n",
       "0    war, bedankte sich Sauer mit einer Ehrenurku...   \n",
       "1                    für die zwei \"Lager\" äußerten.    \n",
       "2    zu Heinrich Böll ist, oder ob ihn dieser inn...   \n",
       "3                              Ab sofort erhältlich    \n",
       "4    profilierten Politikern, die auch einmal geg...   \n",
       "\n",
       "                                                 Hit  \\\n",
       "0  Gerade Thiery als \"Querdenker\" habe mit seinen...   \n",
       "1  Der Ehrenvorsitzende der Völklinger CDU, Dr. R...   \n",
       "2  \"Ich fühle mich geschmeichelt\", so der gerührt...   \n",
       "3  Schade, daß das Buch auch auf die Rolle von Fr...   \n",
       "4  Querdenker erzielen aber nie hundertprozentige...   \n",
       "\n",
       "                                        ContextAfter  \\\n",
       "0   Edgar Schuster, Ortsvorsteher von Noswendel u...   \n",
       "1     Angesichts der schon in einem Jahr stattfinde    \n",
       "2   Dennoch, konstatierte Ratlosigkeit auch bei W...   \n",
       "3                            Die Neuerscheinung jed    \n",
       "4   Und auch bei der anstehenden Besetzung der Pl...   \n",
       "\n",
       "                                                Text  \n",
       "0    war, bedankte sich Sauer mit einer Ehrenurku...  \n",
       "1    für die zwei \"Lager\" äußerten. Der Ehrenvors...  \n",
       "2    zu Heinrich Böll ist, oder ob ihn dieser inn...  \n",
       "3  Ab sofort erhältlich Schade, daß das Buch auch...  \n",
       "4    profilierten Politikern, die auch einmal geg...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text zu einer Spalte verbinden\n",
    "\n",
    "columns = ['ContextBefore', 'Hit', 'ContextAfter']\n",
    "\n",
    "df['Text'] = df[columns].astype(str).sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7549, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6uioii_SibZl"
   },
   "outputs": [],
   "source": [
    "# Korpus in 2 Teilkorpora splitten: vor und nach Covid-19 (dem Ausbruch in Deutschland)\n",
    "# hier wurde die Grenze zwischen Januar und Februar 2020 gezogen (es wird sich noch zeigen, inwiefern sich das bewährt)\n",
    "\n",
    "df_before_corona = df.iloc[:4420,:]\n",
    "df_after_corona = df.iloc[4421:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Bibl</th>\n",
       "      <th>ContextBefore</th>\n",
       "      <th>Hit</th>\n",
       "      <th>ContextAfter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>laz_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Landshuter Zeitung, 01.02.2020</td>\n",
       "      <td>einen Familienschatz:</td>\n",
       "      <td>Es sind beeindruckende Dokumente eines unbeugs...</td>\n",
       "      <td>Die Veröffentlichung der</td>\n",
       "      <td>einen Familienschatz: Es sind beeindruckende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>ta_regional</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Thüringer Allgemeine, 01.02.2020</td>\n",
       "      <td>Essen und trinken in der Kirche</td>\n",
       "      <td>Vogelsberger Kirchgemeinde und Querdenker halt...</td>\n",
       "      <td>Annett Kletzke</td>\n",
       "      <td>Essen und trinken in der Kirche Vogelsberger K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>mume_regional</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Münchner Merkur, 04.02.2020</td>\n",
       "      <td>wie den Familienschatz:</td>\n",
       "      <td>Es sind beeindruckende Dokumente eines unbeugs...</td>\n",
       "      <td>Die Veröffentlichung der</td>\n",
       "      <td>wie den Familienschatz: Es sind beeindrucken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>frt_regional</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Fränkischer Tag, 06.02.2020</td>\n",
       "      <td>Danach werde für ihn als Bürgermeister definit...</td>\n",
       "      <td>Pöhnlein hat sich über die Jahre einen Namen a...</td>\n",
       "      <td>Immer wieder durchstreift er im Urlaub die Bu...</td>\n",
       "      <td>Danach werde für ihn als Bürgermeister definit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>frt_regional</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>Zeitung</td>\n",
       "      <td>Fränkischer Tag, 06.02.2020</td>\n",
       "      <td>Diskussionsscheu werde er aber nicht sein, ver...</td>\n",
       "      <td>Denn vor dem Leben nach der Politik würde er f...</td>\n",
       "      <td></td>\n",
       "      <td>Diskussionsscheu werde er aber nicht sein, ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Corpus        Date    Genre                              Bibl  \\\n",
       "4421   laz_regional  2020-02-01  Zeitung    Landshuter Zeitung, 01.02.2020   \n",
       "4422    ta_regional  2020-02-01  Zeitung  Thüringer Allgemeine, 01.02.2020   \n",
       "4423  mume_regional  2020-02-04  Zeitung       Münchner Merkur, 04.02.2020   \n",
       "4424   frt_regional  2020-02-06  Zeitung       Fränkischer Tag, 06.02.2020   \n",
       "4425   frt_regional  2020-02-06  Zeitung       Fränkischer Tag, 06.02.2020   \n",
       "\n",
       "                                          ContextBefore  \\\n",
       "4421                             einen Familienschatz:    \n",
       "4422                   Essen und trinken in der Kirche    \n",
       "4423                           wie den Familienschatz:    \n",
       "4424  Danach werde für ihn als Bürgermeister definit...   \n",
       "4425  Diskussionsscheu werde er aber nicht sein, ver...   \n",
       "\n",
       "                                                    Hit  \\\n",
       "4421  Es sind beeindruckende Dokumente eines unbeugs...   \n",
       "4422  Vogelsberger Kirchgemeinde und Querdenker halt...   \n",
       "4423  Es sind beeindruckende Dokumente eines unbeugs...   \n",
       "4424  Pöhnlein hat sich über die Jahre einen Namen a...   \n",
       "4425  Denn vor dem Leben nach der Politik würde er f...   \n",
       "\n",
       "                                           ContextAfter  \\\n",
       "4421                         Die Veröffentlichung der     \n",
       "4422                                     Annett Kletzke   \n",
       "4423                         Die Veröffentlichung der     \n",
       "4424   Immer wieder durchstreift er im Urlaub die Bu...   \n",
       "4425                                                      \n",
       "\n",
       "                                                   Text  \n",
       "4421    einen Familienschatz: Es sind beeindruckende...  \n",
       "4422  Essen und trinken in der Kirche Vogelsberger K...  \n",
       "4423    wie den Familienschatz: Es sind beeindrucken...  \n",
       "4424  Danach werde für ihn als Bürgermeister definit...  \n",
       "4425  Diskussionsscheu werde er aber nicht sein, ver...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_corona.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hilfsfunktionen zur Vorbereitung der Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text_column(df, column):\n",
    "    \"\"\"\n",
    "    transforms the Dataframe-column in a lemmatized string\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    for i in df[column]:\n",
    "        doc = nlp(i)\n",
    "        lemmas = ' '.join([x.lemma_ for x in doc])\n",
    "        text = text + lemmas\n",
    "    return text\n",
    "\n",
    "\n",
    "def sentence_to_wordlist(raw:str):\n",
    "    \"\"\"\n",
    "    cleans and tokenizes the sentences\n",
    "    \"\"\"\n",
    "    text = re.sub('[^A-Za-z_äÄöÖüÜß]',' ', raw).split()\n",
    "    filtered_text = [word for word in text if word not in stopwords]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def prepare_text(raw_text):\n",
    "    \"\"\"\n",
    "    returns a list of tokenized sentences\n",
    "    \"\"\"\n",
    "    raw_sentences = tokenizer.tokenize(str(raw_text).lower())    \n",
    "    tokenized_sentences = Parallel(n_jobs=-1)(delayed(sentence_to_wordlist)(raw_sentence) for raw_sentence in raw_sentences)\n",
    "    phrases = Phrases(tokenized_sentences)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = list(bigram[tokenized_sentences])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des ersten Texts (vor Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uVMUJzlpibZo",
    "outputId": "d9d2a45d-3e51-41e2-83a8-decaed115ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ideenreiche', 'innovative', 'firma', 'brache', 'heimat', 'finden', 'gelingen', 'branchen', 'mix', 'installieren', 'raum', 'querdenker', 'kreativ', 'lassen', 'bringen', 'gründerzentrum', 'stadt', 'völklingen', 'erhoffen', 'neu', 'impuls']\n"
     ]
    }
   ],
   "source": [
    "text = lemmatize_text_column(df_before_corona, 'Text')\n",
    "sentences = prepare_text(text)\n",
    "\n",
    "# sentences ist eine Liste von tokenisierten Sätzen, zum Beispiel:\n",
    "print(sentences[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vorbereitung des zweiten Texts (nach Covid-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zeitgleich', 'aktion', 'oma_rechts', 'finden', 'steinwurf', 'entfernen', 'münsterplatz', 'erneute', 'anti_corona', 'kundgebung', 'querdenker', 'schwarzwald', 'baar', 'statt']\n"
     ]
    }
   ],
   "source": [
    "text2 = lemmatize_text_column(df_after_corona, 'Text')\n",
    "sentences2 = prepare_text(text2)\n",
    "\n",
    "print(sentences2[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training von Word2Vec auf den Text vor Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HI1V5EARibZo"
   },
   "outputs": [],
   "source": [
    "# Paramter setzen\n",
    "workers = 4                      # Use these many worker threads to train the model (=faster training with multicore machines)\n",
    "seed = 42                        # Seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gWLaiZ5cibZq"
   },
   "outputs": [],
   "source": [
    "# Ordner anlegen zum Abspeichern von trainierten Modellen\n",
    "if not os.path.exists('../trained_models'):\n",
    "    os.makedirs('../trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kpbrlbf0ibZq",
    "outputId": "1f537e5c-add4-40c4-8b31-49c6f8869309"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "w2v_bc = Word2Vec(sentences=sentences,                   \n",
    "                 vector_size=300,          # Dimensionality of the word vectors\n",
    "                 window=10,                # The maximum distance between the current and predicted word within a sentence\n",
    "                 min_count=3,              # (int, optional) – The model ignores all words with total frequency lower than this\n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,         # Learning rate will linearly drop to min_alpha as training progresses\n",
    "                 sg=1,                     # Training algorithm: skip-gram if sg=1, otherwise CBOW\n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH8M_UkAibZr"
   },
   "source": [
    "## Training von Word2Vec auf den Text nach Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Gfy3LgWyibZt",
    "outputId": "0962a7be-cecd-4c1f-a1e0-ba52aff1fdc1"
   },
   "outputs": [],
   "source": [
    "w2v_ac = Word2Vec(sentences=sentences2,                   \n",
    "                 vector_size=300,                \n",
    "                 window=10,              \n",
    "                 min_count=3,             \n",
    "                 workers=workers, \n",
    "                 min_alpha=0.0001,                                                    \n",
    "                 sg=1,                     \n",
    "                 seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle speichern\n",
    "w2v_bc.save(os.path.join('../trained_models', 'w2v_bc_querdenker.model'))\n",
    "w2v_ac.save(os.path.join('../trained_models', 'w2v_ac_querdenker.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration und Vergleich der Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainierte Modelle laden\n",
    "w2v_bc = Word2Vec.load(os.path.join('../trained_models', 'w2v_bc_querdenker.model'))\n",
    "w2v_ac = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_querdenker.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "okTISay5ibZv",
    "outputId": "8f2fe288-c8ba-4abc-881f-a2ed7c6e69f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sache', 0.98907470703125),\n",
       " ('weit', 0.9885329008102417),\n",
       " ('dafür', 0.9882361888885498),\n",
       " ('ding', 0.9880260229110718),\n",
       " ('mitglied', 0.987959086894989),\n",
       " ('bieten', 0.9879337549209595),\n",
       " ('nehmen', 0.9879003167152405),\n",
       " ('tag', 0.9878810048103333),\n",
       " ('ziehen', 0.9878451824188232),\n",
       " ('liegen', 0.9876826405525208),\n",
       " ('vielleicht', 0.9876161217689514),\n",
       " ('preis', 0.9875643849372864),\n",
       " ('welch', 0.9875577688217163),\n",
       " ('seit_jahr', 0.987551748752594),\n",
       " ('müssen', 0.9875342845916748),\n",
       " ('region', 0.9875229001045227),\n",
       " ('hoch', 0.9874721169471741),\n",
       " ('manch', 0.9874322414398193),\n",
       " ('wenig', 0.9874059557914734),\n",
       " ('zeit', 0.9873632192611694),\n",
       " ('wohl', 0.9873336553573608),\n",
       " ('halten', 0.9873067140579224),\n",
       " ('politik', 0.9872918725013733),\n",
       " ('grund', 0.9872702360153198),\n",
       " ('gesellschaft', 0.9872584939002991)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' vor Covid-19\n",
    "w2v_bc.wv.most_similar(positive=['querdenker'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "twofLe79ibZw",
    "outputId": "baea5bc0-fcdb-4e83-c22c-37853c505e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tausende', 0.9983060359954834),\n",
       " ('zahlreich', 0.9982943534851074),\n",
       " ('auflösen', 0.9982912540435791),\n",
       " ('hundert', 0.9982864260673523),\n",
       " ('kommend', 0.9982734322547913),\n",
       " ('corona_schutzmaßnahmen', 0.9982596039772034),\n",
       " ('mahnwache', 0.9982582926750183),\n",
       " ('bodensee', 0.9982216358184814),\n",
       " ('verlaufen', 0.9982146620750427),\n",
       " ('silvester', 0.9981962442398071),\n",
       " ('mobilisieren', 0.998186469078064),\n",
       " ('sachsen', 0.9981706142425537),\n",
       " ('cockerwiese', 0.9981564879417419),\n",
       " ('nachdem', 0.9981463551521301),\n",
       " ('kundgebungen', 0.998138964176178),\n",
       " ('zunächst', 0.998138427734375),\n",
       " ('ernannt_querdenker', 0.9981381893157959),\n",
       " ('angekündigt', 0.9981364011764526),\n",
       " ('zug', 0.9981335997581482),\n",
       " ('toleranz', 0.9981313347816467),\n",
       " ('ostern', 0.9981269836425781),\n",
       " ('mehrer_tausend', 0.9981257915496826),\n",
       " ('jeweils', 0.998124361038208),\n",
       " ('versammlungsleiter', 0.9981224536895752),\n",
       " ('polizeieinsatz', 0.9981224536895752)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' nach Covid-19\n",
    "w2v_ac.wv.most_similar(positive=['querdenker'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gefährlich', 0.999016523361206),\n",
       " ('sogar', 0.9989219903945923),\n",
       " ('leugnen', 0.9989145398139954),\n",
       " ('angst', 0.9989040493965149),\n",
       " ('denken', 0.9988967776298523),\n",
       " ('bezeichnen', 0.9988879561424255),\n",
       " ('äußern', 0.9988608360290527),\n",
       " ('politiker', 0.9988545179367065),\n",
       " ('land', 0.9988386034965515),\n",
       " ('tun', 0.9988346695899963)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_ac.wv.most_similar(positive=['virus'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausrichtung der beiden Embedding-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Updatet script: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
    "    Procrustes align two gensim models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
    "    # base_embed.init_sims(replace=True)\n",
    "    # other_embed.init_sims(replace=True)\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "    \n",
    "    # re-filling the normed vectors\n",
    "    in_base_embed.wv.fill_norms(force=True)\n",
    "    in_other_embed.wv.fill_norms(force=True)\n",
    "\n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n",
    "\n",
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1785 1785\n",
      "1785 1785\n"
     ]
    }
   ],
   "source": [
    "# Ausrichtung des \"After-Corona-Modells\" an das \"Before-Corona-Modell\"\n",
    "\n",
    "w2v_ac_al = smart_procrustes_align_gensim(w2v_bc, w2v_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speichern\n",
    "w2v_ac_al.save(os.path.join('../trained_models', 'w2v_ac_al_querdenker.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus-Ähnlichkeit zwischen den Vektoren der beiden Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laden\n",
    "w2v_ac_al = Word2Vec.load(os.path.join('../trained_models', 'w2v_ac_al_querdenker.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zahlreich', 0.9982943534851074),\n",
       " ('hundert', 0.9982864856719971),\n",
       " ('kommend', 0.9982733726501465),\n",
       " ('bodensee', 0.9982216358184814),\n",
       " ('sachsen', 0.9981706738471985),\n",
       " ('nachdem', 0.9981464147567749),\n",
       " ('zunächst', 0.998138427734375),\n",
       " ('zug', 0.998133659362793),\n",
       " ('jeweils', 0.998124361038208),\n",
       " ('berichten', 0.998106062412262),\n",
       " ('vergangen', 0.9981006979942322),\n",
       " ('leipziger', 0.9980988502502441),\n",
       " ('zehn', 0.9980970621109009),\n",
       " ('ort', 0.9980946779251099),\n",
       " ('regensburg', 0.9980934262275696),\n",
       " ('erlauben', 0.9980932474136353),\n",
       " ('abhalten', 0.998091459274292),\n",
       " ('ei', 0.998089075088501),\n",
       " ('stuttgart', 0.9980887770652771),\n",
       " ('hamburg', 0.998087465763092),\n",
       " ('f', 0.998075008392334),\n",
       " ('begründen', 0.9980601668357849),\n",
       " ('dezember', 0.9980531930923462),\n",
       " ('laden', 0.9980515241622925),\n",
       " ('gericht', 0.9980473518371582)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ähnliche Wörter zu 'querdenker' nach Covid-19\n",
    "w2v_ac_al.wv.most_similar(positive=['querdenker'], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829095602035522"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_querdenker_bc = w2v_bc.wv['querdenker']  \n",
    "vector_querdenker_ac_al = w2v_ac_al.wv['querdenker'] \n",
    "\n",
    "cosine_querdenker = 1 - spatial.distance.cosine(vector_querdenker_bc, vector_querdenker_ac_al)\n",
    "cosine_querdenker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990604519844055"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versuch mit unverfänglichen Wörtern\n",
    "\n",
    "vector_deutschland_bc = w2v_bc.wv['deutschland']  \n",
    "vector_deutschland_ac_al = w2v_ac_al.wv['deutschland'] \n",
    "\n",
    "cosine_deutschland = 1 - spatial.distance.cosine(vector_deutschland_bc, vector_deutschland_ac_al)\n",
    "cosine_deutschland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964999556541443"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_schreiben_bc = w2v_bc.wv['schreiben']  \n",
    "vector_schreiben_ac_al = w2v_ac_al.wv['schreiben'] \n",
    "\n",
    "cosine_schreiben = 1 - spatial.distance.cosine(vector_schreiben_bc, vector_schreiben_ac_al)\n",
    "cosine_schreiben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784703850746155"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_sagen_bc = w2v_bc.wv['sagen']  \n",
    "vector_sagen_ac_al = w2v_ac_al.wv['sagen'] \n",
    "\n",
    "cosine_sagen = 1 - spatial.distance.cosine(vector_sagen_bc, vector_sagen_ac_al)\n",
    "cosine_sagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959689974784851"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mann_bc = w2v_bc.wv['mann']  \n",
    "vector_mann_ac_al = w2v_ac_al.wv['mann'] \n",
    "\n",
    "cosine_mann = 1 - spatial.distance.cosine(vector_mann_bc, vector_mann_ac_al)\n",
    "cosine_mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99891597032547"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_frau_bc = w2v_bc.wv['frau']  \n",
    "vector_frau_ac_al = w2v_ac_al.wv['frau'] \n",
    "\n",
    "cosine_frau = 1 - spatial.distance.cosine(vector_frau_bc, vector_frau_ac_al)\n",
    "cosine_frau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9909916520118713"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_mensch_bc = w2v_bc.wv['mensch']  \n",
    "vector_mensch_ac_al = w2v_ac_al.wv['mensch'] \n",
    "\n",
    "cosine_mensch = 1 - spatial.distance.cosine(vector_mensch_bc, vector_mensch_ac_al)\n",
    "cosine_mensch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992215037345886"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_montag_bc = w2v_bc.wv['montag']  \n",
    "vector_montag_ac_al = w2v_ac_al.wv['montag'] \n",
    "\n",
    "cosine_montag = 1 - spatial.distance.cosine(vector_montag_bc, vector_montag_ac_al)\n",
    "cosine_montag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### durchschnittliche Cosinus-Ähnlichkeit, Standardweichung und 'Normalbereich'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- von allen Wörtern/Vektoren, die in beiden Modellen vorkommen jeweils die Cosinus-Ähnlichkeit berechnen (also zueinander zwischen den Modellen)\n",
    "- durchschnittliche Ähnlichkeit und Standardabweichung berechnen, um einen 'Normalbereich' zu ermitteln\n",
    "- liegt der Wert der Cosinus-Ähnlichkeit (desselben Lemmas zwischen den Modellen) unter dem Normalbereich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle Wörter, die in beiden Modellen vorkommmen\n",
    "\n",
    "vocab_bc = set(w2v_bc.wv.index_to_key)\n",
    "vocab_ac_al = set(w2v_ac_al.wv.index_to_key)\n",
    "\n",
    "common_vocab = vocab_bc & vocab_ac_al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1785"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosinus-Ähnlichkeit zwischen dem Wort in den beiden Modellen berechnen\n",
    "\n",
    "cosines = {}\n",
    "\n",
    "for word in common_vocab:\n",
    "    vector_bc = w2v_bc.wv[word]  \n",
    "    vector_ac_al = w2v_ac_al.wv[word] \n",
    "    cosine = 1 - spatial.distance.cosine(vector_bc, vector_ac_al)\n",
    "    cosines[word] = cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nacht</th>\n",
       "      <td>0.999097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jedenfalls</th>\n",
       "      <td>0.998793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offensichtlich</th>\n",
       "      <td>0.999297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>struktur</th>\n",
       "      <td>0.999387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wünschen</th>\n",
       "      <td>0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kontern</th>\n",
       "      <td>0.999008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vorsitzender</th>\n",
       "      <td>0.998664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bürger</th>\n",
       "      <td>0.999203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angst</th>\n",
       "      <td>0.999328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erhalten</th>\n",
       "      <td>0.998360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1785 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cosine\n",
       "nacht           0.999097\n",
       "jedenfalls      0.998793\n",
       "offensichtlich  0.999297\n",
       "struktur        0.999387\n",
       "wünschen        0.999251\n",
       "...                  ...\n",
       "kontern         0.999008\n",
       "vorsitzender    0.998664\n",
       "bürger          0.999203\n",
       "angst           0.999328\n",
       "erhalten        0.998360\n",
       "\n",
       "[1785 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df = pd.DataFrame.from_dict(cosines, orient='index', columns=['cosine'])\n",
    "cosine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972867226734214"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# durchschnittliche Cosinus-Ähnlichkeit der Wörter der beiden Modelle \n",
    "\n",
    "statistics.mean(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013924214701904173"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardabweichung\n",
    "\n",
    "statistics.stdev(cosine_df['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Normalbereich der Cosinus-Ähnlichkeit liegt über 0.9833625079715173\n"
     ]
    }
   ],
   "source": [
    "# 'Normalbereich' der Cosinus-Ähnlichkeit\n",
    "\n",
    "border = statistics.mean(cosine_df['cosine']) - statistics.stdev(cosine_df['cosine'])\n",
    "\n",
    "print('der Normalbereich der Cosinus-Ähnlichkeit liegt über', border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>offene_gesprächsrunde</th>\n",
       "      <td>0.718973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zweifler_bibelmüde</th>\n",
       "      <td>0.723392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.725256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humanist_atheist</th>\n",
       "      <td>0.727345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdu</th>\n",
       "      <td>0.932601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etc</th>\n",
       "      <td>0.934535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partei</th>\n",
       "      <td>0.938574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_uhr</th>\n",
       "      <td>0.939847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bürgerwache</th>\n",
       "      <td>0.945615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mehr</th>\n",
       "      <td>0.949109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gelten</th>\n",
       "      <td>0.951039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spd</th>\n",
       "      <td>0.954771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immer</th>\n",
       "      <td>0.956556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politisch</th>\n",
       "      <td>0.957226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolandstr</th>\n",
       "      <td>0.963451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idee</th>\n",
       "      <td>0.966328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gehen</th>\n",
       "      <td>0.969038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schon</th>\n",
       "      <td>0.969117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kommen</th>\n",
       "      <td>0.970332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gut</th>\n",
       "      <td>0.972348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stadt</th>\n",
       "      <td>0.973315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwei</th>\n",
       "      <td>0.973334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leben</th>\n",
       "      <td>0.977111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.978084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sagen</th>\n",
       "      <td>0.978470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>querdenkern</th>\n",
       "      <td>0.978722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stellen</th>\n",
       "      <td>0.979346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samstag</th>\n",
       "      <td>0.980215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groß</th>\n",
       "      <td>0.980461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stehen</th>\n",
       "      <td>0.981091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         cosine\n",
       "offene_gesprächsrunde  0.718973\n",
       "zweifler_bibelmüde     0.723392\n",
       "u                      0.725256\n",
       "humanist_atheist       0.727345\n",
       "cdu                    0.932601\n",
       "etc                    0.934535\n",
       "partei                 0.938574\n",
       "ab_uhr                 0.939847\n",
       "bürgerwache            0.945615\n",
       "mehr                   0.949109\n",
       "gelten                 0.951039\n",
       "spd                    0.954771\n",
       "immer                  0.956556\n",
       "politisch              0.957226\n",
       "rolandstr              0.963451\n",
       "idee                   0.966328\n",
       "gehen                  0.969038\n",
       "schon                  0.969117\n",
       "kommen                 0.970332\n",
       "gut                    0.972348\n",
       "stadt                  0.973315\n",
       "zwei                   0.973334\n",
       "leben                  0.977111\n",
       "all                    0.978084\n",
       "sagen                  0.978470\n",
       "querdenkern            0.978722\n",
       "stellen                0.979346\n",
       "samstag                0.980215\n",
       "groß                   0.980461\n",
       "stehen                 0.981091"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardabweichung erscheint hoch\n",
    "# DF aufsteigend sortieren und die ersten 30 Zeilen ausgeben, um die 'Ausreißer' anzuschauen\n",
    "\n",
    "cosine_df.sort_values(by=['cosine'], axis=0).iloc[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Versuch: Ausreißer (hier mal alle unter 0,9) rauslöschen und erneut den Normalbereich berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cdu</th>\n",
       "      <td>0.932601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etc</th>\n",
       "      <td>0.934535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partei</th>\n",
       "      <td>0.938574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_uhr</th>\n",
       "      <td>0.939847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bürgerwache</th>\n",
       "      <td>0.945615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cosine\n",
       "cdu          0.932601\n",
       "etc          0.934535\n",
       "partei       0.938574\n",
       "ab_uhr       0.939847\n",
       "bürgerwache  0.945615"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_df_new = cosine_df.sort_values(by=['cosine'], axis=0).iloc[4:,:]\n",
    "cosine_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979010860549139"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.mean(cosine_df_new['cosine']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005076390578291385"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistics.stdev(cosine_df_new['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Normalbereich der Cosinus-Ähnlichkeit liegt über 0.9928246954766226\n"
     ]
    }
   ],
   "source": [
    "# neuer 'Normalbereich' der Cosinus-Ähnlichkeit\n",
    "\n",
    "border = statistics.mean(cosine_df_new['cosine']) - statistics.stdev(cosine_df_new['cosine'])\n",
    "\n",
    "print('der Normalbereich der Cosinus-Ähnlichkeit liegt über', border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_querdenker < border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Cosinus-Ähnlichkeit zwischen den beiden Vektoren für 'Querdenker' liegt unterhalb des Normalbereichs. <br>\n",
    "Die Hypothese kann als verifiziert gelten. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fasttext Corona.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
